{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries to run the code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>id</th>\n",
       "      <th>replyToUID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @kahruveldesign: …he wrote on Jan. 23. “My ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-09 22:25:07</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1259248057582940161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>thinkalot</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  favorited  \\\n",
       "1  RT @kahruveldesign: …he wrote on Jan. 23. “My ...      False   \n",
       "\n",
       "   favoriteCount replyToSN             created  truncated  replyToSID  \\\n",
       "1              0       NaN 2020-05-09 22:25:07      False         NaN   \n",
       "\n",
       "                    id  replyToUID  \\\n",
       "1  1259248057582940161         NaN   \n",
       "\n",
       "                                        statusSource screenName  retweetCount  \\\n",
       "1  <a href=\"http://twitter.com/download/android\" ...  thinkalot             1   \n",
       "\n",
       "   isRetweet  retweeted  longitude  latitude  \n",
       "1       True      False        NaN       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"US-BasedCovid19Tweets.xlsx\") \n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.8, subjectivity=0.9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "t = TextBlob(\"He is a cheater. i hate him\")\n",
    "t.sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>id</th>\n",
       "      <th>replyToUID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@kahruveldesign: …he wrote Jan. 23. “My phones...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-09 22:25:07</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1259248057582940161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>thinkalot</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please Share This Warning. It's Not About Popu...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-09 22:22:13</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1259247327904256003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>DRandall</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  favorited  \\\n",
       "1  @kahruveldesign: …he wrote Jan. 23. “My phones...      False   \n",
       "2  Please Share This Warning. It's Not About Popu...      False   \n",
       "\n",
       "   favoriteCount replyToSN             created  truncated  replyToSID  \\\n",
       "1              0       NaN 2020-05-09 22:25:07      False         NaN   \n",
       "2              0       NaN 2020-05-09 22:22:13       True         NaN   \n",
       "\n",
       "                    id  replyToUID  \\\n",
       "1  1259248057582940161         NaN   \n",
       "2  1259247327904256003         NaN   \n",
       "\n",
       "                                        statusSource screenName  retweetCount  \\\n",
       "1  <a href=\"http://twitter.com/download/android\" ...  thinkalot             1   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   DRandall             0   \n",
       "\n",
       "   isRetweet  retweeted  longitude  latitude  \n",
       "1       True      False        NaN       NaN  \n",
       "2      False      False        NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#applying pre-processing steps to remove stopwords and words of size less than 2\n",
    "data['text'] = data['text'].apply(lambda x: x.split())\n",
    "wordsEng = stopwords.words('english')\n",
    "data['text'] = data['text'].apply(lambda x:[item for item in x if item not in wordsEng])\n",
    "data['text'] = data['text'].apply(lambda x: [w for w in x if len(w)>2])\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x))\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')\n",
    "TEXT=[]\n",
    "#Rating=[]\n",
    "for i in range(len(data)):\n",
    "    #if data['cetagory'][i]=='Racing':\n",
    "    review = re.sub('[^a-zA-Z]', ' ',data['text'][i])\n",
    "    #review = re.sub('[/(){}\\[\\]\\|@!,;]', ' ',data['reviews'][i])\n",
    "    #review = re.sub('[^0-9a-zA-Z #+_♥️]', ' ',data['reviews'][i])#Remove bad symbols\n",
    "    review = re.sub(r'\\d+', '',review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [token for token in review if token not in sw]\n",
    "    review=' '.join(review)\n",
    "    TEXT.append(review)\n",
    "    #Rating.append(data['rating'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "NegativeReview=[]\n",
    "PositiveReview=[]\n",
    "from textblob import TextBlob\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(data)):   \n",
    "    #message_text = 'i hate you'\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    b = TextBlob(data.text[i])\n",
    "    #scores = sid.polarity_scores(data.reviews[i])\n",
    "    value=b.sentiment[0]\n",
    "    if value<=0:\n",
    "        NegativeReview.append('Negative')\n",
    "    else:\n",
    "        PositiveReview.append('Positive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "Sentiment=[]\n",
    "\n",
    "from textblob import TextBlob\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(data)):   \n",
    "    #message_text = 'i hate you'\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    b = TextBlob(data.text[i])\n",
    "    #scores = sid.polarity_scores(data.reviews[i])\n",
    "    value=b.sentiment[0]\n",
    "    if value<=0:\n",
    "        Sentiment.append(0)\n",
    "    else:\n",
    "        Sentiment.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX,ttX,trY,ttY = train_test_split(TEXT,Sentiment, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = np.array(trX)\n",
    "trY = np.array(trY)\n",
    "ttX = np.array(ttX)\n",
    "ttY = np.array(ttY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples shape : (8300,)\n",
      "Train labels shape  : (8300,)\n",
      "Test samples shape  : (3558,)\n",
      "Test labels shape   : (3558,)\n"
     ]
    }
   ],
   "source": [
    "print ('Train samples shape :', trX.shape)\n",
    "print ('Train labels shape  :', trY.shape)\n",
    "print ('Test samples shape  :', ttX.shape)\n",
    "print ('Test labels shape   :', ttY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_RANGE = (1,1)\n",
    "TOP_K = 30000\n",
    "TOKEN_MODE = 'word'\n",
    "MIN_DOC_FREQ = 2\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
    "    kwargs = {\n",
    "        'ngram_range' : NGRAM_RANGE,\n",
    "        'dtype' : 'int32',\n",
    "        'strip_accents' : 'unicode',\n",
    "        'decode_error' : 'replace',\n",
    "        'analyzer' : TOKEN_MODE,\n",
    "        'min_df' : MIN_DOC_FREQ,\n",
    "    }\n",
    "    \n",
    "    # Learn Vocab from train texts and vectorize train and val sets\n",
    "    tfidf_vectorizer = TfidfVectorizer(**kwargs)\n",
    "    x_train = tfidf_vectorizer.fit_transform(train_texts)\n",
    "    x_val = tfidf_vectorizer.transform(val_texts)\n",
    "    \n",
    "    # Select best k features, with feature importance measured by f_classif\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train).astype('float32')\n",
    "    x_val = selector.transform(x_val).astype('float32')\n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_layer_units_and_activation(num_classes):\n",
    "    if num_classes == 2:\n",
    "        activation = 'sigmoid'\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        units = num_classes\n",
    "    return units, activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    op_units, op_activation = get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "    \n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "        \n",
    "    model.add(Dense(units=op_units, activation=op_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trX, trY, ttX, ttY):\n",
    "    import keras_metrics\n",
    "    learning_rate=1e-2\n",
    "    epochs=50\n",
    "    batch_size=128\n",
    "    layers=4\n",
    "    units=200\n",
    "    dropout_rate=0.5\n",
    "    num_classes = 2\n",
    "    # Get the data\n",
    "    trX, trY, ttX, ttY\n",
    "\n",
    "\n",
    "    # Vectorize the data\n",
    "    x_train, x_val = ngram_vectorize(trX, trY, ttX)\n",
    "\n",
    "    # Create model instance\n",
    "    model = mlp_model(layers, units=units, dropout_rate=dropout_rate,\n",
    "                      input_shape=x_train.shape[1:], num_classes=num_classes)\n",
    "\n",
    "    # Compile model with parameters\n",
    "    if num_classes == 2:\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc','mae',keras_metrics.precision(), keras_metrics.recall()])\n",
    "\n",
    "    # Create callback for early stopping on validation loss. If the loss does\n",
    "    # not decrease on two consecutive tries, stop training\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)]\n",
    "    score=[]\n",
    "    # Train and validate model\n",
    "    History = model.fit(x_train, trY, epochs=epochs, validation_data=(x_val, ttY),\n",
    "                        verbose=2, batch_size=batch_size, callbacks=callbacks)\n",
    "    score=model.evaluate(x_val,ttY)\n",
    "    return score\n",
    "\n",
    "# Print results\n",
    "#history = History.history\n",
    "#val_acc = history['val_acc'][-1]\n",
    "#val_loss = history['val_loss'][-1]\n",
    "#val_precision=history['val_precision'][-1]\n",
    "#val_recall=history['val_recall'][-1]\n",
    "#print ('Validation accuracy: {acc}, loss: {loss}'.format(\n",
    "#        acc=val_acc, loss=val_loss))\n",
    "# Plot accuracy\n",
    "#plt.plot(History.history['acc'])\n",
    "#plt.plot(History.history['val_acc'])\n",
    "#plt.title('Model Accuracy')\n",
    "#plt.ylabel('Accuracy')\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "# Plot loss\n",
    "#plt.plot(History.history['loss'])\n",
    "#plt.plot(History.history['val_loss'])\n",
    "#plt.title('Model Loss')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/50\n",
      " - 12s - loss: 0.4491 - acc: 0.7888 - mean_absolute_error: 0.2901 - precision: 0.7723 - recall: 0.4909 - val_loss: 0.2848 - val_acc: 0.8806 - val_mean_absolute_error: 0.2035 - val_precision: 0.9666 - val_recall: 0.6641\n",
      "Epoch 2/50\n",
      " - 6s - loss: 0.2937 - acc: 0.8796 - mean_absolute_error: 0.1799 - precision: 0.8794 - recall: 0.7432 - val_loss: 0.2300 - val_acc: 0.9089 - val_mean_absolute_error: 0.1547 - val_precision: 0.9397 - val_recall: 0.7743\n",
      "Epoch 3/50\n",
      " - 4s - loss: 0.2437 - acc: 0.9041 - mean_absolute_error: 0.1452 - precision: 0.9083 - recall: 0.7967 - val_loss: 0.2137 - val_acc: 0.9157 - val_mean_absolute_error: 0.1325 - val_precision: 0.9372 - val_recall: 0.7986\n",
      "Epoch 4/50\n",
      " - 4s - loss: 0.2285 - acc: 0.9139 - mean_absolute_error: 0.1326 - precision: 0.9054 - recall: 0.8318 - val_loss: 0.2197 - val_acc: 0.9112 - val_mean_absolute_error: 0.1383 - val_precision: 0.9488 - val_recall: 0.7745\n",
      "Epoch 5/50\n",
      " - 4s - loss: 0.2178 - acc: 0.9140 - mean_absolute_error: 0.1273 - precision: 0.9130 - recall: 0.8266 - val_loss: 0.2193 - val_acc: 0.9084 - val_mean_absolute_error: 0.1309 - val_precision: 0.8767 - val_recall: 0.8414\n",
      "3558/3558 [==============================] - 1s 154us/step\n",
      "Printing Fold \n",
      "Loss: 0.21931\n",
      "validation accuracy: 0.90838\n",
      "Precision: 0.87664\n",
      "Recacll: 0.84250\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "score=[]\n",
    "score = evaluate_model(trX, trY, ttX, ttY)\n",
    "print(\"Printing Fold \" % range(n_folds))\n",
    "print(\"Loss: %.5f\" %(score[0]))\n",
    "print(\"validation accuracy: %.5f\" % (score[1]))\n",
    "print(\"Precision: %.5f\" %(score[3]))\n",
    "print(\"Recacll: %.5f\" %(score[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5634 - acc: 0.6952 - mean_absolute_error: 0.3991 - precision: 0.3130 - recall: 0.0978 - val_loss: 0.3919 - val_acc: 0.8612 - val_mean_absolute_error: 0.2743 - val_precision: 0.9771 - val_recall: 0.5972\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.2616 - acc: 0.9116 - mean_absolute_error: 0.1731 - precision: 0.9091 - recall: 0.8233 - val_loss: 0.2422 - val_acc: 0.9098 - val_mean_absolute_error: 0.1213 - val_precision: 0.9221 - val_recall: 0.7977\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.1350 - acc: 0.9496 - mean_absolute_error: 0.0814 - precision: 0.9347 - recall: 0.9146 - val_loss: 0.2595 - val_acc: 0.9120 - val_mean_absolute_error: 0.1062 - val_precision: 0.9355 - val_recall: 0.7922\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0946 - acc: 0.9652 - mean_absolute_error: 0.0549 - precision: 0.9528 - recall: 0.9444 - val_loss: 0.2538 - val_acc: 0.9129 - val_mean_absolute_error: 0.1028 - val_precision: 0.9022 - val_recall: 0.8299\n",
      "3558/3558 [==============================] - 0s 114us/step\n",
      "Printing Fold \n",
      "Loss: 0.25382\n",
      "validation accuracy: 0.91287\n",
      "Precision: 0.90105\n",
      "Recacll: 0.83422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.5553 - acc: 0.7051 - mean_absolute_error: 0.3939 - precision: 0.3758 - recall: 0.1251 - val_loss: 0.3850 - val_acc: 0.8465 - val_mean_absolute_error: 0.2706 - val_precision: 0.9692 - val_recall: 0.5704\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.2449 - acc: 0.9136 - mean_absolute_error: 0.1607 - precision: 0.9053 - recall: 0.8275 - val_loss: 0.2324 - val_acc: 0.9036 - val_mean_absolute_error: 0.1371 - val_precision: 0.8465 - val_recall: 0.8806\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.1253 - acc: 0.9511 - mean_absolute_error: 0.0769 - precision: 0.9377 - recall: 0.9152 - val_loss: 0.2337 - val_acc: 0.9120 - val_mean_absolute_error: 0.1097 - val_precision: 0.8909 - val_recall: 0.8489\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0913 - acc: 0.9676 - mean_absolute_error: 0.0537 - precision: 0.9586 - recall: 0.9448 - val_loss: 0.2523 - val_acc: 0.9117 - val_mean_absolute_error: 0.1030 - val_precision: 0.8997 - val_recall: 0.8356\n",
      "3558/3558 [==============================] - 0s 105us/step\n",
      "Printing Fold \n",
      "Loss: 0.25228\n",
      "validation accuracy: 0.91175\n",
      "Precision: 0.89765\n",
      "Recacll: 0.83877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.5549 - acc: 0.7157 - mean_absolute_error: 0.3976 - precision: 0.5167 - recall: 0.1858 - val_loss: 0.3444 - val_acc: 0.8547 - val_mean_absolute_error: 0.2357 - val_precision: 0.9391 - val_recall: 0.5988\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.2327 - acc: 0.9108 - mean_absolute_error: 0.1453 - precision: 0.9030 - recall: 0.8275 - val_loss: 0.2338 - val_acc: 0.9092 - val_mean_absolute_error: 0.1311 - val_precision: 0.8996 - val_recall: 0.8184\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.1306 - acc: 0.9508 - mean_absolute_error: 0.0789 - precision: 0.9395 - recall: 0.9145 - val_loss: 0.2331 - val_acc: 0.9106 - val_mean_absolute_error: 0.1113 - val_precision: 0.8959 - val_recall: 0.8286\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0987 - acc: 0.9616 - mean_absolute_error: 0.0578 - precision: 0.9498 - recall: 0.9363 - val_loss: 0.2587 - val_acc: 0.9120 - val_mean_absolute_error: 0.1032 - val_precision: 0.9144 - val_recall: 0.8128\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0791 - acc: 0.9683 - mean_absolute_error: 0.0470 - precision: 0.9577 - recall: 0.9486 - val_loss: 0.2598 - val_acc: 0.9103 - val_mean_absolute_error: 0.1010 - val_precision: 0.8943 - val_recall: 0.8322\n",
      "3558/3558 [==============================] - 0s 101us/step\n",
      "Printing Fold \n",
      "Loss: 0.25983\n",
      "validation accuracy: 0.91034\n",
      "Precision: 0.89429\n",
      "Recacll: 0.83066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5557 - acc: 0.7255 - mean_absolute_error: 0.3985 - precision: 0.7324 - recall: 0.2144 - val_loss: 0.3191 - val_acc: 0.8640 - val_mean_absolute_error: 0.2225 - val_precision: 0.9469 - val_recall: 0.6357\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.2265 - acc: 0.9113 - mean_absolute_error: 0.1413 - precision: 0.8994 - recall: 0.8254 - val_loss: 0.2166 - val_acc: 0.9132 - val_mean_absolute_error: 0.1207 - val_precision: 0.9108 - val_recall: 0.8245\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.1256 - acc: 0.9539 - mean_absolute_error: 0.0763 - precision: 0.9449 - recall: 0.9151 - val_loss: 0.2157 - val_acc: 0.9151 - val_mean_absolute_error: 0.1048 - val_precision: 0.8896 - val_recall: 0.8565\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0948 - acc: 0.9649 - mean_absolute_error: 0.0559 - precision: 0.9538 - recall: 0.9406 - val_loss: 0.2278 - val_acc: 0.9106 - val_mean_absolute_error: 0.1026 - val_precision: 0.8745 - val_recall: 0.8615\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0759 - acc: 0.9731 - mean_absolute_error: 0.0431 - precision: 0.9658 - recall: 0.9524 - val_loss: 0.2381 - val_acc: 0.9126 - val_mean_absolute_error: 0.0959 - val_precision: 0.8918 - val_recall: 0.8441\n",
      "3558/3558 [==============================] - 0s 101us/step\n",
      "Printing Fold \n",
      "Loss: 0.23806\n",
      "validation accuracy: 0.91259\n",
      "Precision: 0.89179\n",
      "Recacll: 0.84079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5708 - acc: 0.6845 - mean_absolute_error: 0.4070 - precision: 0.3307 - recall: 0.0829 - val_loss: 0.3953 - val_acc: 0.8305 - val_mean_absolute_error: 0.2753 - val_precision: 0.9825 - val_recall: 0.4939\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.2753 - acc: 0.9012 - mean_absolute_error: 0.1820 - precision: 0.9071 - recall: 0.7925 - val_loss: 0.2142 - val_acc: 0.9165 - val_mean_absolute_error: 0.1295 - val_precision: 0.8741 - val_recall: 0.8716\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.1331 - acc: 0.9511 - mean_absolute_error: 0.0807 - precision: 0.9342 - recall: 0.9190 - val_loss: 0.2214 - val_acc: 0.9160 - val_mean_absolute_error: 0.1068 - val_precision: 0.8623 - val_recall: 0.8830\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0965 - acc: 0.9634 - mean_absolute_error: 0.0563 - precision: 0.9532 - recall: 0.9390 - val_loss: 0.2288 - val_acc: 0.9168 - val_mean_absolute_error: 0.0968 - val_precision: 0.8721 - val_recall: 0.8733\n",
      "3558/3558 [==============================] - 0s 105us/step\n",
      "Printing Fold \n",
      "Loss: 0.22880\n",
      "validation accuracy: 0.91681\n",
      "Precision: 0.87350\n",
      "Recacll: 0.87241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5634 - acc: 0.7065 - mean_absolute_error: 0.4023 - precision: 0.4532 - recall: 0.1599 - val_loss: 0.3602 - val_acc: 0.8505 - val_mean_absolute_error: 0.2489 - val_precision: 0.9580 - val_recall: 0.5806\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.2325 - acc: 0.9099 - mean_absolute_error: 0.1492 - precision: 0.9036 - recall: 0.8196 - val_loss: 0.2213 - val_acc: 0.9101 - val_mean_absolute_error: 0.1225 - val_precision: 0.8928 - val_recall: 0.8324\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.1317 - acc: 0.9504 - mean_absolute_error: 0.0784 - precision: 0.9410 - recall: 0.9111 - val_loss: 0.2255 - val_acc: 0.9103 - val_mean_absolute_error: 0.1080 - val_precision: 0.8853 - val_recall: 0.8424\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0978 - acc: 0.9641 - mean_absolute_error: 0.0579 - precision: 0.9515 - recall: 0.9405 - val_loss: 0.2490 - val_acc: 0.9162 - val_mean_absolute_error: 0.1002 - val_precision: 0.9042 - val_recall: 0.8386\n",
      "3558/3558 [==============================] - 0s 114us/step\n",
      "Printing Fold \n",
      "Loss: 0.24898\n",
      "validation accuracy: 0.91625\n",
      "Precision: 0.90261\n",
      "Recacll: 0.83728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5663 - acc: 0.7076 - mean_absolute_error: 0.4065 - precision: 0.5068 - recall: 0.1944 - val_loss: 0.3391 - val_acc: 0.8544 - val_mean_absolute_error: 0.2316 - val_precision: 0.9674 - val_recall: 0.5748\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.2310 - acc: 0.9106 - mean_absolute_error: 0.1460 - precision: 0.9035 - recall: 0.8274 - val_loss: 0.2236 - val_acc: 0.9137 - val_mean_absolute_error: 0.1175 - val_precision: 0.9361 - val_recall: 0.7912\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.1283 - acc: 0.9533 - mean_absolute_error: 0.0769 - precision: 0.9489 - recall: 0.9123 - val_loss: 0.2138 - val_acc: 0.9193 - val_mean_absolute_error: 0.1008 - val_precision: 0.9081 - val_recall: 0.8405\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0929 - acc: 0.9654 - mean_absolute_error: 0.0543 - precision: 0.9567 - recall: 0.9400 - val_loss: 0.2206 - val_acc: 0.9199 - val_mean_absolute_error: 0.0976 - val_precision: 0.8857 - val_recall: 0.8689\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0768 - acc: 0.9720 - mean_absolute_error: 0.0440 - precision: 0.9658 - recall: 0.9512 - val_loss: 0.2349 - val_acc: 0.9191 - val_mean_absolute_error: 0.0968 - val_precision: 0.8709 - val_recall: 0.8843\n",
      "3558/3558 [==============================] - 0s 110us/step\n",
      "Printing Fold \n",
      "Loss: 0.23486\n",
      "validation accuracy: 0.91906\n",
      "Precision: 0.87079\n",
      "Recacll: 0.88284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5654 - acc: 0.6970 - mean_absolute_error: 0.4017 - precision: 0.3677 - recall: 0.1122 - val_loss: 0.3798 - val_acc: 0.8569 - val_mean_absolute_error: 0.2720 - val_precision: 0.9513 - val_recall: 0.6005\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.2505 - acc: 0.9123 - mean_absolute_error: 0.1643 - precision: 0.9142 - recall: 0.8220 - val_loss: 0.2200 - val_acc: 0.9098 - val_mean_absolute_error: 0.1286 - val_precision: 0.8623 - val_recall: 0.8685\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.1297 - acc: 0.9501 - mean_absolute_error: 0.0780 - precision: 0.9392 - recall: 0.9111 - val_loss: 0.2136 - val_acc: 0.9154 - val_mean_absolute_error: 0.1071 - val_precision: 0.8740 - val_recall: 0.8710\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0973 - acc: 0.9633 - mean_absolute_error: 0.0574 - precision: 0.9514 - recall: 0.9393 - val_loss: 0.2218 - val_acc: 0.9174 - val_mean_absolute_error: 0.0972 - val_precision: 0.8803 - val_recall: 0.8711\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0731 - acc: 0.9745 - mean_absolute_error: 0.0423 - precision: 0.9652 - recall: 0.9598 - val_loss: 0.2402 - val_acc: 0.9157 - val_mean_absolute_error: 0.0942 - val_precision: 0.8786 - val_recall: 0.8664\n",
      "3558/3558 [==============================] - 0s 119us/step\n",
      "Printing Fold \n",
      "Loss: 0.24021\n",
      "validation accuracy: 0.91568\n",
      "Precision: 0.87558\n",
      "Recacll: 0.86832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5675 - acc: 0.7005 - mean_absolute_error: 0.4058 - precision: 0.3730 - recall: 0.1309 - val_loss: 0.3672 - val_acc: 0.8654 - val_mean_absolute_error: 0.2596 - val_precision: 0.9597 - val_recall: 0.6242\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.2374 - acc: 0.9104 - mean_absolute_error: 0.1528 - precision: 0.9038 - recall: 0.8235 - val_loss: 0.2167 - val_acc: 0.9160 - val_mean_absolute_error: 0.1176 - val_precision: 0.9078 - val_recall: 0.8382\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.1223 - acc: 0.9542 - mean_absolute_error: 0.0737 - precision: 0.9403 - recall: 0.9222 - val_loss: 0.2138 - val_acc: 0.9148 - val_mean_absolute_error: 0.1061 - val_precision: 0.8749 - val_recall: 0.8738\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0937 - acc: 0.9631 - mean_absolute_error: 0.0563 - precision: 0.9515 - recall: 0.9377 - val_loss: 0.2218 - val_acc: 0.9191 - val_mean_absolute_error: 0.0959 - val_precision: 0.8937 - val_recall: 0.8631\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0807 - acc: 0.9708 - mean_absolute_error: 0.0456 - precision: 0.9588 - recall: 0.9542 - val_loss: 0.2252 - val_acc: 0.9207 - val_mean_absolute_error: 0.0928 - val_precision: 0.8901 - val_recall: 0.8742\n",
      "3558/3558 [==============================] - 0s 114us/step\n",
      "Printing Fold \n",
      "Loss: 0.22518\n",
      "validation accuracy: 0.92074\n",
      "Precision: 0.89102\n",
      "Recacll: 0.86837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5607 - acc: 0.7120 - mean_absolute_error: 0.4015 - precision: 0.4716 - recall: 0.1757 - val_loss: 0.3289 - val_acc: 0.8811 - val_mean_absolute_error: 0.2408 - val_precision: 0.9259 - val_recall: 0.7006\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.2309 - acc: 0.9113 - mean_absolute_error: 0.1451 - precision: 0.8981 - recall: 0.8344 - val_loss: 0.2136 - val_acc: 0.9154 - val_mean_absolute_error: 0.1193 - val_precision: 0.8827 - val_recall: 0.8587\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.1270 - acc: 0.9535 - mean_absolute_error: 0.0762 - precision: 0.9441 - recall: 0.9166 - val_loss: 0.2161 - val_acc: 0.9160 - val_mean_absolute_error: 0.1028 - val_precision: 0.8733 - val_recall: 0.8719\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0953 - acc: 0.9661 - mean_absolute_error: 0.0559 - precision: 0.9618 - recall: 0.9384 - val_loss: 0.2512 - val_acc: 0.9073 - val_mean_absolute_error: 0.1075 - val_precision: 0.8375 - val_recall: 0.8920\n",
      "3558/3558 [==============================] - 0s 101us/step\n",
      "Printing Fold \n",
      "Loss: 0.25117\n",
      "validation accuracy: 0.90725\n",
      "Precision: 0.83746\n",
      "Recacll: 0.89512\n",
      "Estimated Accuracy 0.914 (0.004)\n",
      "Estimated Precision 0.884 (0.019)\n",
      "Estimated Recall 0.857 (0.022)\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "cv_scores, model_history,precision,recall = list(), list(),list(), list()\n",
    "for _ in range(n_folds):\n",
    "    trX,ttX,trY,ttY = train_test_split(TEXT,Sentiment, test_size = 0.3)\n",
    "    trX = np.array(trX)\n",
    "    trY = np.array(trY)\n",
    "    ttX = np.array(ttX)\n",
    "    ttY = np.array(ttY)\n",
    "\n",
    "    # evaluate model\n",
    "    score=[]\n",
    "    score = evaluate_model(trX, trY, ttX, ttY)\n",
    "    print(\"Printing Fold \" % range(n_folds))\n",
    "    print(\"Loss: %.5f\" %(score[0]))\n",
    "    print(\"validation accuracy: %.5f\" % (score[1]))\n",
    "    print(\"Precision: %.5f\" %(score[3]))\n",
    "    print(\"Recacll: %.5f\" %(score[4]))\n",
    "    cv_scores.append(score[1])\n",
    "    precision.append(score[3])\n",
    "    recall.append(score[4])\n",
    "    #model_history.append(model)\n",
    "    \n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "print('Estimated Precision %.3f (%.3f)' % (np.mean(precision), np.std(precision)))\n",
    "print('Estimated Recall %.3f (%.3f)' % (np.mean(recall), np.std(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing all necessary libraries to run the code\n",
    "import re,string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras_metrics\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,Embedding,GlobalMaxPooling1D\n",
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kahruveldesign wrote jan phones ringing need g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please share warning popularity https co wbycg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  kahruveldesign wrote jan phones ringing need g...\n",
       "1  please share warning popularity https co wbycg..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting twitterSentiment[] list into dataframe for serving it to keras tokenizer\n",
    "dataSetFinal = pd.DataFrame(np.array(TEXT))\n",
    "dataSetFinal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSentiment = pd.DataFrame(np.array(Sentiment))\n",
    "dataSentiment.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tensorflow.keras.preprocessing.text.Tokenizer(num_words=2500, lower=True,split=' ',filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(dataSetFinal[0].values)\n",
    "#print(tokenizer.word_index)  # To see the dicstionary\n",
    "X = tokenizer.texts_to_sequences(dataSetFinal[0].values)\n",
    "X = tensorflow.keras.preprocessing.sequence.pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 23, 100)           250000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 345,652\n",
      "Trainable params: 345,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "#Deep Learning Network Structure\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Embedding(2500,100, input_length=X.shape[1]))\n",
    "#model_conv.add(Dropout(0.5))\n",
    "#model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "#model_conv.add(MaxPooling1D(pool_size=4))\n",
    "model_conv.add(LSTM(100))\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(Dense(100, activation='relu'))\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(Dense(50, activation='relu'))\n",
    "model_conv.add(Dropout(0.2))\n",
    "model_conv.add(Dense(2, activation='softmax'))\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_conv.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy','mae','mse',keras_metrics.precision(), keras_metrics.recall()])\n",
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 23, 100)           250000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 23, 64)            32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 11, 64)            20544     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 304,754\n",
      "Trainable params: 304,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "weight_decay = 1e-4\n",
    "#Deep Learning Network Structure\n",
    "model = Sequential()\n",
    "model.add(Embedding(2500,100, input_length=X.shape[1]))\n",
    "model.add(Conv1D(64, 5, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, 5, activation='relu', padding='same'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy','mae','mse',keras_metrics.precision(), keras_metrics.recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/50\n",
      " - 16s - loss: 0.6446 - acc: 0.6573 - mean_absolute_error: 0.4532 - mean_squared_error: 0.2261 - precision: 0.6617 - recall: 0.9878 - val_loss: 0.6335 - val_acc: 0.6684 - val_mean_absolute_error: 0.4399 - val_mean_squared_error: 0.2209 - val_precision: 0.6684 - val_recall: 1.0000\n",
      "Epoch 2/50\n",
      " - 8s - loss: 0.6355 - acc: 0.6624 - mean_absolute_error: 0.4442 - mean_squared_error: 0.2219 - precision: 0.6624 - recall: 1.0000 - val_loss: 0.6285 - val_acc: 0.6684 - val_mean_absolute_error: 0.4482 - val_mean_squared_error: 0.2185 - val_precision: 0.6684 - val_recall: 1.0000\n",
      "Epoch 3/50\n",
      " - 8s - loss: 0.6268 - acc: 0.6636 - mean_absolute_error: 0.4400 - mean_squared_error: 0.2179 - precision: 0.6632 - recall: 1.0000 - val_loss: 0.6143 - val_acc: 0.6684 - val_mean_absolute_error: 0.4469 - val_mean_squared_error: 0.2117 - val_precision: 0.6684 - val_recall: 1.0000\n",
      "Epoch 4/50\n",
      " - 8s - loss: 0.5968 - acc: 0.6946 - mean_absolute_error: 0.4172 - mean_squared_error: 0.2043 - precision: 0.6908 - recall: 0.9756 - val_loss: 0.5615 - val_acc: 0.7150 - val_mean_absolute_error: 0.3750 - val_mean_squared_error: 0.1891 - val_precision: 0.7015 - val_recall: 0.9983\n",
      "Epoch 5/50\n",
      " - 8s - loss: 0.5406 - acc: 0.7434 - mean_absolute_error: 0.3735 - mean_squared_error: 0.1803 - precision: 0.7409 - recall: 0.9420 - val_loss: 0.4765 - val_acc: 0.7934 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.1538 - val_precision: 0.7761 - val_recall: 0.9710\n",
      "Epoch 6/50\n",
      " - 8s - loss: 0.4652 - acc: 0.7904 - mean_absolute_error: 0.3101 - mean_squared_error: 0.1503 - precision: 0.7923 - recall: 0.9263 - val_loss: 0.3957 - val_acc: 0.8311 - val_mean_absolute_error: 0.2551 - val_mean_squared_error: 0.1241 - val_precision: 0.8156 - val_recall: 0.9655\n",
      "Epoch 7/50\n",
      " - 8s - loss: 0.3774 - acc: 0.8394 - mean_absolute_error: 0.2434 - mean_squared_error: 0.1173 - precision: 0.8433 - recall: 0.9305 - val_loss: 0.3185 - val_acc: 0.8648 - val_mean_absolute_error: 0.2036 - val_mean_squared_error: 0.0970 - val_precision: 0.8839 - val_recall: 0.9184\n",
      "Epoch 8/50\n",
      " - 9s - loss: 0.2953 - acc: 0.8849 - mean_absolute_error: 0.1774 - mean_squared_error: 0.0876 - precision: 0.8897 - recall: 0.9433 - val_loss: 0.3341 - val_acc: 0.8738 - val_mean_absolute_error: 0.1747 - val_mean_squared_error: 0.0994 - val_precision: 0.8633 - val_recall: 0.9638\n",
      "Epoch 9/50\n",
      " - 8s - loss: 0.2466 - acc: 0.9045 - mean_absolute_error: 0.1472 - mean_squared_error: 0.0712 - precision: 0.9071 - recall: 0.9534 - val_loss: 0.2580 - val_acc: 0.9106 - val_mean_absolute_error: 0.1242 - val_mean_squared_error: 0.0725 - val_precision: 0.9173 - val_recall: 0.9521\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.2265 - acc: 0.9184 - mean_absolute_error: 0.1290 - mean_squared_error: 0.0639 - precision: 0.9230 - recall: 0.9567 - val_loss: 0.2607 - val_acc: 0.9047 - val_mean_absolute_error: 0.1362 - val_mean_squared_error: 0.0738 - val_precision: 0.9348 - val_recall: 0.9218\n",
      "Epoch 11/50\n",
      " - 8s - loss: 0.1795 - acc: 0.9390 - mean_absolute_error: 0.1014 - mean_squared_error: 0.0492 - precision: 0.9416 - recall: 0.9680 - val_loss: 0.2727 - val_acc: 0.9067 - val_mean_absolute_error: 0.1154 - val_mean_squared_error: 0.0744 - val_precision: 0.9040 - val_recall: 0.9626\n",
      "Epoch 12/50\n",
      " - 8s - loss: 0.1682 - acc: 0.9445 - mean_absolute_error: 0.0933 - mean_squared_error: 0.0445 - precision: 0.9461 - recall: 0.9714 - val_loss: 0.2694 - val_acc: 0.9036 - val_mean_absolute_error: 0.1201 - val_mean_squared_error: 0.0739 - val_precision: 0.9343 - val_recall: 0.9205\n",
      "Epoch 13/50\n",
      " - 9s - loss: 0.3960 - acc: 0.8561 - mean_absolute_error: 0.2332 - mean_squared_error: 0.1157 - precision: 0.8466 - recall: 0.9560 - val_loss: 0.3319 - val_acc: 0.8763 - val_mean_absolute_error: 0.1824 - val_mean_squared_error: 0.0971 - val_precision: 0.8676 - val_recall: 0.9617\n",
      "Epoch 14/50\n",
      " - 8s - loss: 0.3413 - acc: 0.8800 - mean_absolute_error: 0.2034 - mean_squared_error: 0.0988 - precision: 0.8721 - recall: 0.9596 - val_loss: 0.3073 - val_acc: 0.8879 - val_mean_absolute_error: 0.1808 - val_mean_squared_error: 0.0887 - val_precision: 0.8938 - val_recall: 0.9445\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.2233 - acc: 0.9227 - mean_absolute_error: 0.1291 - mean_squared_error: 0.0613 - precision: 0.9178 - recall: 0.9702 - val_loss: 0.2639 - val_acc: 0.9117 - val_mean_absolute_error: 0.1179 - val_mean_squared_error: 0.0710 - val_precision: 0.9031 - val_recall: 0.9722\n",
      "Epoch 16/50\n",
      " - 8s - loss: 0.1688 - acc: 0.9452 - mean_absolute_error: 0.0910 - mean_squared_error: 0.0445 - precision: 0.9435 - recall: 0.9756 - val_loss: 0.2728 - val_acc: 0.9182 - val_mean_absolute_error: 0.1072 - val_mean_squared_error: 0.0675 - val_precision: 0.9353 - val_recall: 0.9428\n",
      "Epoch 17/50\n",
      " - 8s - loss: 0.1510 - acc: 0.9522 - mean_absolute_error: 0.0799 - mean_squared_error: 0.0394 - precision: 0.9502 - recall: 0.9791 - val_loss: 0.2529 - val_acc: 0.9185 - val_mean_absolute_error: 0.1094 - val_mean_squared_error: 0.0661 - val_precision: 0.9387 - val_recall: 0.9394\n",
      "Epoch 18/50\n",
      " - 9s - loss: 0.1298 - acc: 0.9581 - mean_absolute_error: 0.0674 - mean_squared_error: 0.0337 - precision: 0.9562 - recall: 0.9816 - val_loss: 0.2517 - val_acc: 0.9244 - val_mean_absolute_error: 0.0934 - val_mean_squared_error: 0.0623 - val_precision: 0.9313 - val_recall: 0.9575\n",
      "Epoch 19/50\n",
      " - 8s - loss: 0.1185 - acc: 0.9663 - mean_absolute_error: 0.0617 - mean_squared_error: 0.0294 - precision: 0.9642 - recall: 0.9856 - val_loss: 0.2627 - val_acc: 0.9233 - val_mean_absolute_error: 0.0982 - val_mean_squared_error: 0.0649 - val_precision: 0.9395 - val_recall: 0.9462\n",
      "Epoch 20/50\n",
      " - 9s - loss: 0.1108 - acc: 0.9659 - mean_absolute_error: 0.0565 - mean_squared_error: 0.0279 - precision: 0.9655 - recall: 0.9836 - val_loss: 0.2689 - val_acc: 0.9247 - val_mean_absolute_error: 0.0902 - val_mean_squared_error: 0.0652 - val_precision: 0.9367 - val_recall: 0.9516\n",
      "Epoch 21/50\n",
      " - 8s - loss: 0.1085 - acc: 0.9675 - mean_absolute_error: 0.0559 - mean_squared_error: 0.0268 - precision: 0.9665 - recall: 0.9851 - val_loss: 0.2767 - val_acc: 0.9236 - val_mean_absolute_error: 0.0895 - val_mean_squared_error: 0.0647 - val_precision: 0.9377 - val_recall: 0.9487\n",
      "Epoch 22/50\n",
      " - 9s - loss: 0.0979 - acc: 0.9718 - mean_absolute_error: 0.0496 - mean_squared_error: 0.0238 - precision: 0.9703 - recall: 0.9876 - val_loss: 0.2575 - val_acc: 0.9280 - val_mean_absolute_error: 0.0831 - val_mean_squared_error: 0.0607 - val_precision: 0.9303 - val_recall: 0.9647\n",
      "Epoch 23/50\n",
      " - 9s - loss: 0.0947 - acc: 0.9736 - mean_absolute_error: 0.0480 - mean_squared_error: 0.0230 - precision: 0.9728 - recall: 0.9878 - val_loss: 0.2798 - val_acc: 0.9320 - val_mean_absolute_error: 0.0782 - val_mean_squared_error: 0.0620 - val_precision: 0.9317 - val_recall: 0.9693\n",
      "Epoch 24/50\n",
      " - 8s - loss: 0.0906 - acc: 0.9751 - mean_absolute_error: 0.0436 - mean_squared_error: 0.0218 - precision: 0.9740 - recall: 0.9887 - val_loss: 0.2860 - val_acc: 0.9278 - val_mean_absolute_error: 0.0830 - val_mean_squared_error: 0.0641 - val_precision: 0.9348 - val_recall: 0.9588\n",
      "Epoch 25/50\n",
      " - 8s - loss: 0.0885 - acc: 0.9748 - mean_absolute_error: 0.0430 - mean_squared_error: 0.0211 - precision: 0.9733 - recall: 0.9891 - val_loss: 0.2713 - val_acc: 0.9283 - val_mean_absolute_error: 0.0842 - val_mean_squared_error: 0.0625 - val_precision: 0.9338 - val_recall: 0.9609\n",
      "Epoch 26/50\n",
      " - 9s - loss: 0.0816 - acc: 0.9777 - mean_absolute_error: 0.0403 - mean_squared_error: 0.0189 - precision: 0.9763 - recall: 0.9904 - val_loss: 0.3033 - val_acc: 0.9238 - val_mean_absolute_error: 0.0843 - val_mean_squared_error: 0.0663 - val_precision: 0.9330 - val_recall: 0.9546\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.0798 - acc: 0.9773 - mean_absolute_error: 0.0393 - mean_squared_error: 0.0191 - precision: 0.9750 - recall: 0.9913 - val_loss: 0.3174 - val_acc: 0.9264 - val_mean_absolute_error: 0.0854 - val_mean_squared_error: 0.0659 - val_precision: 0.9416 - val_recall: 0.9487\n",
      "Epoch 28/50\n",
      " - 9s - loss: 0.0822 - acc: 0.9765 - mean_absolute_error: 0.0403 - mean_squared_error: 0.0196 - precision: 0.9749 - recall: 0.9900 - val_loss: 0.2987 - val_acc: 0.9275 - val_mean_absolute_error: 0.0795 - val_mean_squared_error: 0.0643 - val_precision: 0.9274 - val_recall: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      " - 8s - loss: 0.0775 - acc: 0.9799 - mean_absolute_error: 0.0352 - mean_squared_error: 0.0175 - precision: 0.9774 - recall: 0.9925 - val_loss: 0.3094 - val_acc: 0.9289 - val_mean_absolute_error: 0.0790 - val_mean_squared_error: 0.0654 - val_precision: 0.9265 - val_recall: 0.9706\n",
      "Epoch 30/50\n",
      " - 9s - loss: 0.0691 - acc: 0.9820 - mean_absolute_error: 0.0335 - mean_squared_error: 0.0156 - precision: 0.9811 - recall: 0.9920 - val_loss: 0.3143 - val_acc: 0.9219 - val_mean_absolute_error: 0.0828 - val_mean_squared_error: 0.0679 - val_precision: 0.9300 - val_recall: 0.9550\n",
      "Epoch 31/50\n",
      " - 9s - loss: 0.0668 - acc: 0.9837 - mean_absolute_error: 0.0305 - mean_squared_error: 0.0145 - precision: 0.9815 - recall: 0.9942 - val_loss: 0.3801 - val_acc: 0.9157 - val_mean_absolute_error: 0.0955 - val_mean_squared_error: 0.0756 - val_precision: 0.9448 - val_recall: 0.9281\n",
      "Epoch 32/50\n",
      " - 9s - loss: 0.0691 - acc: 0.9825 - mean_absolute_error: 0.0325 - mean_squared_error: 0.0153 - precision: 0.9813 - recall: 0.9925 - val_loss: 0.3286 - val_acc: 0.9250 - val_mean_absolute_error: 0.0803 - val_mean_squared_error: 0.0681 - val_precision: 0.9272 - val_recall: 0.9634\n",
      "Epoch 33/50\n",
      " - 8s - loss: 0.0730 - acc: 0.9807 - mean_absolute_error: 0.0336 - mean_squared_error: 0.0167 - precision: 0.9792 - recall: 0.9920 - val_loss: 0.3131 - val_acc: 0.9303 - val_mean_absolute_error: 0.0775 - val_mean_squared_error: 0.0638 - val_precision: 0.9319 - val_recall: 0.9664\n",
      "Epoch 34/50\n",
      " - 9s - loss: 0.0741 - acc: 0.9794 - mean_absolute_error: 0.0353 - mean_squared_error: 0.0172 - precision: 0.9781 - recall: 0.9911 - val_loss: 0.3880 - val_acc: 0.9179 - val_mean_absolute_error: 0.0917 - val_mean_squared_error: 0.0735 - val_precision: 0.9442 - val_recall: 0.9323\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.0674 - acc: 0.9825 - mean_absolute_error: 0.0310 - mean_squared_error: 0.0150 - precision: 0.9811 - recall: 0.9927 - val_loss: 0.3285 - val_acc: 0.9252 - val_mean_absolute_error: 0.0807 - val_mean_squared_error: 0.0675 - val_precision: 0.9171 - val_recall: 0.9765\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.0701 - acc: 0.9808 - mean_absolute_error: 0.0334 - mean_squared_error: 0.0162 - precision: 0.9800 - recall: 0.9913 - val_loss: 0.3081 - val_acc: 0.9278 - val_mean_absolute_error: 0.0789 - val_mean_squared_error: 0.0643 - val_precision: 0.9278 - val_recall: 0.9672\n",
      "Epoch 37/50\n",
      " - 8s - loss: 0.0679 - acc: 0.9822 - mean_absolute_error: 0.0325 - mean_squared_error: 0.0153 - precision: 0.9808 - recall: 0.9925 - val_loss: 0.3314 - val_acc: 0.9247 - val_mean_absolute_error: 0.0820 - val_mean_squared_error: 0.0669 - val_precision: 0.9418 - val_recall: 0.9458\n",
      "Epoch 38/50\n",
      " - 8s - loss: 0.0633 - acc: 0.9831 - mean_absolute_error: 0.0288 - mean_squared_error: 0.0143 - precision: 0.9825 - recall: 0.9922 - val_loss: 0.3169 - val_acc: 0.9244 - val_mean_absolute_error: 0.0822 - val_mean_squared_error: 0.0668 - val_precision: 0.9327 - val_recall: 0.9558\n",
      "Epoch 39/50\n",
      " - 8s - loss: 0.0591 - acc: 0.9855 - mean_absolute_error: 0.0279 - mean_squared_error: 0.0130 - precision: 0.9843 - recall: 0.9940 - val_loss: 0.3643 - val_acc: 0.9233 - val_mean_absolute_error: 0.0821 - val_mean_squared_error: 0.0691 - val_precision: 0.9387 - val_recall: 0.9470\n",
      "Epoch 40/50\n",
      " - 8s - loss: 0.0553 - acc: 0.9853 - mean_absolute_error: 0.0258 - mean_squared_error: 0.0125 - precision: 0.9836 - recall: 0.9944 - val_loss: 0.4452 - val_acc: 0.9143 - val_mean_absolute_error: 0.0944 - val_mean_squared_error: 0.0771 - val_precision: 0.9505 - val_recall: 0.9197\n",
      "Epoch 41/50\n",
      " - 8s - loss: 0.0555 - acc: 0.9863 - mean_absolute_error: 0.0256 - mean_squared_error: 0.0123 - precision: 0.9850 - recall: 0.9944 - val_loss: 0.3891 - val_acc: 0.9233 - val_mean_absolute_error: 0.0820 - val_mean_squared_error: 0.0706 - val_precision: 0.9391 - val_recall: 0.9466\n",
      "Epoch 42/50\n",
      " - 8s - loss: 0.0568 - acc: 0.9845 - mean_absolute_error: 0.0268 - mean_squared_error: 0.0131 - precision: 0.9838 - recall: 0.9929 - val_loss: 0.3638 - val_acc: 0.9250 - val_mean_absolute_error: 0.0803 - val_mean_squared_error: 0.0680 - val_precision: 0.9356 - val_recall: 0.9533\n",
      "Epoch 43/50\n",
      " - 10s - loss: 0.0533 - acc: 0.9860 - mean_absolute_error: 0.0251 - mean_squared_error: 0.0121 - precision: 0.9856 - recall: 0.9935 - val_loss: 0.4530 - val_acc: 0.9154 - val_mean_absolute_error: 0.0933 - val_mean_squared_error: 0.0764 - val_precision: 0.9505 - val_recall: 0.9214\n",
      "Epoch 44/50\n",
      " - 8s - loss: 0.0577 - acc: 0.9837 - mean_absolute_error: 0.0263 - mean_squared_error: 0.0132 - precision: 0.9829 - recall: 0.9927 - val_loss: 0.3703 - val_acc: 0.9241 - val_mean_absolute_error: 0.0802 - val_mean_squared_error: 0.0684 - val_precision: 0.9359 - val_recall: 0.9516\n",
      "Epoch 45/50\n",
      " - 8s - loss: 0.0583 - acc: 0.9828 - mean_absolute_error: 0.0282 - mean_squared_error: 0.0137 - precision: 0.9823 - recall: 0.9918 - val_loss: 0.3929 - val_acc: 0.9230 - val_mean_absolute_error: 0.0835 - val_mean_squared_error: 0.0705 - val_precision: 0.9424 - val_recall: 0.9424\n",
      "Epoch 46/50\n",
      " - 8s - loss: 0.0533 - acc: 0.9861 - mean_absolute_error: 0.0247 - mean_squared_error: 0.0120 - precision: 0.9857 - recall: 0.9935 - val_loss: 0.4209 - val_acc: 0.9210 - val_mean_absolute_error: 0.0887 - val_mean_squared_error: 0.0736 - val_precision: 0.9456 - val_recall: 0.9357\n",
      "Epoch 47/50\n",
      " - 8s - loss: 0.0511 - acc: 0.9877 - mean_absolute_error: 0.0236 - mean_squared_error: 0.0107 - precision: 0.9863 - recall: 0.9953 - val_loss: 0.4422 - val_acc: 0.9196 - val_mean_absolute_error: 0.0876 - val_mean_squared_error: 0.0748 - val_precision: 0.9444 - val_recall: 0.9348\n",
      "Epoch 48/50\n",
      " - 8s - loss: 0.0496 - acc: 0.9870 - mean_absolute_error: 0.0226 - mean_squared_error: 0.0108 - precision: 0.9866 - recall: 0.9938 - val_loss: 0.4152 - val_acc: 0.9188 - val_mean_absolute_error: 0.0876 - val_mean_squared_error: 0.0743 - val_precision: 0.9431 - val_recall: 0.9348\n",
      "Epoch 49/50\n",
      " - 8s - loss: 0.0560 - acc: 0.9839 - mean_absolute_error: 0.0257 - mean_squared_error: 0.0130 - precision: 0.9839 - recall: 0.9918 - val_loss: 0.3584 - val_acc: 0.9221 - val_mean_absolute_error: 0.0842 - val_mean_squared_error: 0.0705 - val_precision: 0.9318 - val_recall: 0.9533\n",
      "Epoch 50/50\n",
      " - 9s - loss: 0.0475 - acc: 0.9877 - mean_absolute_error: 0.0228 - mean_squared_error: 0.0105 - precision: 0.9867 - recall: 0.9949 - val_loss: 0.3871 - val_acc: 0.9216 - val_mean_absolute_error: 0.0811 - val_mean_squared_error: 0.0711 - val_precision: 0.9282 - val_recall: 0.9567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x9a6b311fd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LSTM\n",
    "batch_size=64\n",
    "Y = pd.get_dummies(dataSentiment[0]).values\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.30)\n",
    "#Here we train the Network.\n",
    "pred=model_conv.fit(X_train, Y_train, batch_size =batch_size, epochs =50, verbose =2,validation_data=(X_valid,Y_valid))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.39\n",
      "validation accuracy: 0.92\n",
      "Precision: 0.93\n",
      "Recacll: 0.96\n",
      "Mean Absolute Error: 0.08\n",
      "Mean Squared Error: 0.07\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "score=[]\n",
    "score=model_conv.evaluate(X_valid,Y_valid,verbose=2,batch_size=batch_size)\n",
    "#keras.metrics.binary_accuracy(Y_valid,pred)\n",
    "print(\"score: %.2f\" %(score[0]))\n",
    "print(\"validation accuracy: %.2f\" % (score[1]))\n",
    "print(\"Precision: %.2f\" %(score[4]))\n",
    "print(\"Recacll: %.2f\" %(score[5]))\n",
    "print(\"Mean Absolute Error: %.2f\" % (score[2]))\n",
    "print(\"Mean Squared Error: %.2f\" % (score[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8300 samples, validate on 3558 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "batch_size=64\n",
    "Y = pd.get_dummies(dataSentiment[0]).values\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.30)\n",
    "#Here we train the Network.\n",
    "pred=model.fit(X_train, Y_train, batch_size =batch_size, epochs =50, verbose =2,validation_data=(X_valid,Y_valid))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7876\n",
      "3982\n"
     ]
    }
   ],
   "source": [
    "print(len(NegativeReview))\n",
    "print(len(PositiveReview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "NegativeReviewSentimentIntensityAnalyzer=[]\n",
    "PositiveReviewSentimentIntensityAnalyzer=[]\n",
    "from textblob import TextBlob\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(data)):   \n",
    "    #message_text = 'i hate you'\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    b = sid.polarity_scores(data.text[i])\n",
    "    #scores = sid.polarity_scores(data.reviews[i])\n",
    "    value=b['compound']\n",
    "    if value<=0:\n",
    "        NegativeReviewSentimentIntensityAnalyzer.append('Negative')\n",
    "    else:\n",
    "        PositiveReviewSentimentIntensityAnalyzer.append('Positive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "SentimentIntensity=[]\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(data)):   \n",
    "    #message_text = 'i hate you'\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    b = sid.polarity_scores(data.text[i])\n",
    "    #scores = sid.polarity_scores(data.reviews[i])\n",
    "    value=b['compound']\n",
    "    if value<=0:\n",
    "        SentimentIntensity.append('Negative')\n",
    "    else:\n",
    "        SentimentIntensity.append('Positive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8889\n",
      "2969\n"
     ]
    }
   ],
   "source": [
    "print(len(NegativeReviewSentimentIntensityAnalyzer))\n",
    "print(len(PositiveReviewSentimentIntensityAnalyzer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = SentimentIntensity\n",
    "X = TEXT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Sentiment\n",
    "X = TEXT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = SentimentIntensity\n",
    "X = TEXT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Sentiment\n",
    "X = TEXT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.9198988195615514\n",
      "Extra Tree\n",
      "0.947442383361439\n",
      "GBM\n",
      "0.8653738055087128\n",
      "LR\n",
      "0.8991006183249016\n",
      "NB\n",
      "0.8892636312535133\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF TextBlob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1,random_state=2)\n",
    "clf= LogisticRegression()\n",
    "gnb = BernoulliNB()\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "predsGB = gb.fit(X_train, y_train).predict(X_test)\n",
    "predsLR = clf.fit(X_train, y_train).predict(X_test)\n",
    "predsGNB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "predsETC = etc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(\"Extra Tree\")\n",
    "print(accuracy_score(y_test, predsETC))\n",
    "print(\"GBM\")\n",
    "print(accuracy_score(y_test, predsGB))\n",
    "print(\"LR\")\n",
    "print(accuracy_score(y_test, predsLR))\n",
    "print(\"NB\")\n",
    "print(accuracy_score(y_test, predsGNB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.8974142776840922\n",
      "Extra Tree\n",
      "0.9305789769533446\n",
      "GBM\n",
      "0.852726250702642\n",
      "LR\n",
      "0.8839235525576167\n",
      "NB\n",
      "0.8875772906127037\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Sentiment Intensity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1,random_state=2)\n",
    "clf= LogisticRegression()\n",
    "gnb = BernoulliNB()\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "predsGB = gb.fit(X_train, y_train).predict(X_test)\n",
    "predsLR = clf.fit(X_train, y_train).predict(X_test)\n",
    "predsGNB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "predsETC = etc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(\"Extra Tree\")\n",
    "print(accuracy_score(y_test, predsETC))\n",
    "print(\"GBM\")\n",
    "print(accuracy_score(y_test, predsGB))\n",
    "print(\"LR\")\n",
    "print(accuracy_score(y_test, predsLR))\n",
    "print(\"NB\")\n",
    "print(accuracy_score(y_test, predsGNB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.925238898257448\n",
      "Extra Tree\n",
      "0.9406970207982013\n",
      "GBM\n",
      "0.8603147835862844\n",
      "LR\n",
      "0.9249578414839797\n",
      "NB\n",
      "0.8788645306351883\n"
     ]
    }
   ],
   "source": [
    "#COuntVectorizer TextBlob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1,random_state=2)\n",
    "clf= LogisticRegression()\n",
    "gnb = BernoulliNB()\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "predsGB = gb.fit(X_train, y_train).predict(X_test)\n",
    "predsLR = clf.fit(X_train, y_train).predict(X_test)\n",
    "predsGNB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "predsETC = etc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(\"Extra Tree\")\n",
    "print(accuracy_score(y_test, predsETC))\n",
    "print(\"GBM\")\n",
    "print(accuracy_score(y_test, predsGB))\n",
    "print(\"LR\")\n",
    "print(accuracy_score(y_test, predsLR))\n",
    "print(\"NB\")\n",
    "print(accuracy_score(y_test, predsGNB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.9131534569983136\n",
      "Extra Tree\n",
      "0.927487352445194\n",
      "GBM\n",
      "0.8532883642495784\n",
      "LR\n",
      "0.9168071950534008\n",
      "NB\n",
      "0.883080382237212\n"
     ]
    }
   ],
   "source": [
    "#COuntVectorizer Intensity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1,random_state=2)\n",
    "clf= LogisticRegression()\n",
    "gnb = BernoulliNB()\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "predsGB = gb.fit(X_train, y_train).predict(X_test)\n",
    "predsLR = clf.fit(X_train, y_train).predict(X_test)\n",
    "predsGNB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "predsETC = etc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(\"Extra Tree\")\n",
    "print(accuracy_score(y_test, predsETC))\n",
    "print(\"GBM\")\n",
    "print(accuracy_score(y_test, predsGB))\n",
    "print(\"LR\")\n",
    "print(accuracy_score(y_test, predsLR))\n",
    "print(\"NB\")\n",
    "print(accuracy_score(y_test, predsGNB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Classifier\n",
      "0.9378864530635188\n",
      "Voting Classifier LR+SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924114671163575\n"
     ]
    }
   ],
   "source": [
    "#count Vectorizer TextBlob\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "print(\"Stochastic Gradient Classifier\")\n",
    "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
    "predSGD=calibrated_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predSGD))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "print(\"Voting Classifier LR+SGD\")\n",
    "clf2 = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "clf1 = LogisticRegression()\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('sgd', clf2)],voting='hard')\n",
    "predictionVC=eclf1.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predictionVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Classifier\n",
      "0.9238336143901068\n",
      "Voting Classifier LR+SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918212478920742\n"
     ]
    }
   ],
   "source": [
    "#count Vectorizer Intensity\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "print(\"Stochastic Gradient Classifier\")\n",
    "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
    "predSGD=calibrated_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predSGD))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "print(\"Voting Classifier LR+SGD\")\n",
    "clf2 = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "clf1 = LogisticRegression()\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('sgd', clf2)],voting='hard')\n",
    "predictionVC=eclf1.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predictionVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Classifier\n",
      "0.9401349072512648\n",
      "Voting Classifier LR+SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9002248454187746\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF TextBlob\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "print(\"Stochastic Gradient Classifier\")\n",
    "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
    "predSGD=calibrated_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predSGD))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "print(\"Voting Classifier LR+SGD\")\n",
    "clf2 = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "clf1 = LogisticRegression()\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('sgd', clf2)],voting='hard')\n",
    "predictionVC=eclf1.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predictionVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Classifier\n",
      "0.9243957279370433\n",
      "Voting Classifier LR+SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883080382237212\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Sentiment Intensity\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "print(\"Stochastic Gradient Classifier\")\n",
    "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
    "predSGD=calibrated_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predSGD))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "print(\"Voting Classifier LR+SGD\")\n",
    "clf2 = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "clf1 = LogisticRegression()\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('sgd', clf2)],voting='hard')\n",
    "predictionVC=eclf1.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predictionVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.99      0.91      2359\n",
      "    Positive       0.96      0.63      0.76      1199\n",
      "\n",
      "    accuracy                           0.87      3558\n",
      "   macro avg       0.90      0.81      0.83      3558\n",
      "weighted avg       0.88      0.87      0.86      3558\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.98      0.92      2359\n",
      "    Positive       0.94      0.72      0.81      1199\n",
      "\n",
      "    accuracy                           0.89      3558\n",
      "   macro avg       0.91      0.85      0.87      3558\n",
      "weighted avg       0.89      0.89      0.88      3558\n",
      "\n",
      "ETC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.94      0.98      0.96      2359\n",
      "    Positive       0.96      0.88      0.92      1199\n",
      "\n",
      "    accuracy                           0.95      3558\n",
      "   macro avg       0.95      0.93      0.94      3558\n",
      "weighted avg       0.95      0.95      0.95      3558\n",
      "\n",
      "LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.99      0.93      2359\n",
      "    Positive       0.97      0.72      0.83      1199\n",
      "\n",
      "    accuracy                           0.90      3558\n",
      "   macro avg       0.92      0.86      0.88      3558\n",
      "weighted avg       0.91      0.90      0.89      3558\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.96      0.95      0.95      2359\n",
      "    Positive       0.91      0.91      0.91      1199\n",
      "\n",
      "    accuracy                           0.94      3558\n",
      "   macro avg       0.93      0.93      0.93      3558\n",
      "weighted avg       0.94      0.94      0.94      3558\n",
      "\n",
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.99      0.93      2359\n",
      "    Positive       0.98      0.72      0.83      1199\n",
      "\n",
      "    accuracy                           0.90      3558\n",
      "   macro avg       0.93      0.86      0.88      3558\n",
      "weighted avg       0.91      0.90      0.90      3558\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.98      0.94      2359\n",
      "    Positive       0.96      0.79      0.87      1199\n",
      "\n",
      "    accuracy                           0.92      3558\n",
      "   macro avg       0.93      0.89      0.91      3558\n",
      "weighted avg       0.92      0.92      0.92      3558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF TextBlob\n",
    "print(\"GBM\")\n",
    "print(classification_report(y_test,predsGB))\n",
    "print(\"GNB\")\n",
    "print(classification_report(y_test,predsGNB))\n",
    "print(\"ETC\")\n",
    "print(classification_report(y_test,predsETC))\n",
    "print(\"LR\")\n",
    "print(classification_report(y_test,predsLR))\n",
    "print(\"SGD\")\n",
    "print(classification_report(y_test,predSGD))\n",
    "print(\"Voting Classifier\")\n",
    "print(classification_report(y_test,predictionVC))\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_test,preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.99      0.91      2687\n",
      "    Positive       0.91      0.44      0.60       871\n",
      "\n",
      "    accuracy                           0.85      3558\n",
      "   macro avg       0.88      0.71      0.75      3558\n",
      "weighted avg       0.86      0.85      0.83      3558\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.98      0.93      2687\n",
      "    Positive       0.92      0.60      0.72       871\n",
      "\n",
      "    accuracy                           0.89      3558\n",
      "   macro avg       0.90      0.79      0.83      3558\n",
      "weighted avg       0.89      0.89      0.88      3558\n",
      "\n",
      "ETC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.94      0.97      0.95      2687\n",
      "    Positive       0.91      0.80      0.85       871\n",
      "\n",
      "    accuracy                           0.93      3558\n",
      "   macro avg       0.92      0.88      0.90      3558\n",
      "weighted avg       0.93      0.93      0.93      3558\n",
      "\n",
      "LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.99      0.93      2687\n",
      "    Positive       0.94      0.56      0.70       871\n",
      "\n",
      "    accuracy                           0.88      3558\n",
      "   macro avg       0.91      0.78      0.82      3558\n",
      "weighted avg       0.89      0.88      0.87      3558\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.94      0.96      0.95      2687\n",
      "    Positive       0.86      0.82      0.84       871\n",
      "\n",
      "    accuracy                           0.92      3558\n",
      "   macro avg       0.90      0.89      0.90      3558\n",
      "weighted avg       0.92      0.92      0.92      3558\n",
      "\n",
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.99      0.93      2687\n",
      "    Positive       0.94      0.56      0.70       871\n",
      "\n",
      "    accuracy                           0.88      3558\n",
      "   macro avg       0.91      0.77      0.81      3558\n",
      "weighted avg       0.89      0.88      0.87      3558\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.98      0.94      2687\n",
      "    Positive       0.92      0.63      0.75       871\n",
      "\n",
      "    accuracy                           0.90      3558\n",
      "   macro avg       0.91      0.81      0.84      3558\n",
      "weighted avg       0.90      0.90      0.89      3558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Sentiment Intensity\n",
    "print(\"GBM\")\n",
    "print(classification_report(y_test,predsGB))\n",
    "print(\"GNB\")\n",
    "print(classification_report(y_test,predsGNB))\n",
    "print(\"ETC\")\n",
    "print(classification_report(y_test,predsETC))\n",
    "print(\"LR\")\n",
    "print(classification_report(y_test,predsLR))\n",
    "print(\"SGD\")\n",
    "print(classification_report(y_test,predSGD))\n",
    "print(\"Voting Classifier\")\n",
    "print(classification_report(y_test,predictionVC))\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_test,preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.99      0.90      2361\n",
      "    Positive       0.96      0.61      0.75      1197\n",
      "\n",
      "    accuracy                           0.86      3558\n",
      "   macro avg       0.90      0.80      0.83      3558\n",
      "weighted avg       0.88      0.86      0.85      3558\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.97      0.91      2361\n",
      "    Positive       0.93      0.69      0.79      1197\n",
      "\n",
      "    accuracy                           0.88      3558\n",
      "   macro avg       0.90      0.83      0.85      3558\n",
      "weighted avg       0.88      0.88      0.87      3558\n",
      "\n",
      "ETC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.94      0.98      0.96      2361\n",
      "    Positive       0.95      0.87      0.91      1197\n",
      "\n",
      "    accuracy                           0.94      3558\n",
      "   macro avg       0.94      0.92      0.93      3558\n",
      "weighted avg       0.94      0.94      0.94      3558\n",
      "\n",
      "LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.98      0.95      2361\n",
      "    Positive       0.95      0.82      0.88      1197\n",
      "\n",
      "    accuracy                           0.92      3558\n",
      "   macro avg       0.93      0.90      0.91      3558\n",
      "weighted avg       0.93      0.92      0.92      3558\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.94      0.97      0.95      2361\n",
      "    Positive       0.93      0.88      0.91      1197\n",
      "\n",
      "    accuracy                           0.94      3558\n",
      "   macro avg       0.94      0.92      0.93      3558\n",
      "weighted avg       0.94      0.94      0.94      3558\n",
      "\n",
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.98      0.95      2361\n",
      "    Positive       0.96      0.81      0.88      1197\n",
      "\n",
      "    accuracy                           0.92      3558\n",
      "   macro avg       0.94      0.90      0.91      3558\n",
      "weighted avg       0.93      0.92      0.92      3558\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.98      0.95      2361\n",
      "    Positive       0.96      0.81      0.88      1197\n",
      "\n",
      "    accuracy                           0.93      3558\n",
      "   macro avg       0.94      0.90      0.91      3558\n",
      "weighted avg       0.93      0.93      0.92      3558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count Vectorizer TextBlob\n",
    "print(\"GBM\")\n",
    "print(classification_report(y_test,predsGB))\n",
    "print(\"GNB\")\n",
    "print(classification_report(y_test,predsGNB))\n",
    "print(\"ETC\")\n",
    "print(classification_report(y_test,predsETC))\n",
    "print(\"LR\")\n",
    "print(classification_report(y_test,predsLR))\n",
    "print(\"SGD\")\n",
    "print(classification_report(y_test,predSGD))\n",
    "print(\"Voting Classifier\")\n",
    "print(classification_report(y_test,predictionVC))\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_test,preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.99      0.91      2683\n",
      "    Positive       0.91      0.45      0.60       875\n",
      "\n",
      "    accuracy                           0.85      3558\n",
      "   macro avg       0.88      0.72      0.76      3558\n",
      "weighted avg       0.86      0.85      0.83      3558\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.98      0.93      2683\n",
      "    Positive       0.90      0.59      0.71       875\n",
      "\n",
      "    accuracy                           0.88      3558\n",
      "   macro avg       0.89      0.79      0.82      3558\n",
      "weighted avg       0.88      0.88      0.87      3558\n",
      "\n",
      "ETC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.97      0.95      2683\n",
      "    Positive       0.91      0.78      0.84       875\n",
      "\n",
      "    accuracy                           0.93      3558\n",
      "   macro avg       0.92      0.88      0.90      3558\n",
      "weighted avg       0.93      0.93      0.93      3558\n",
      "\n",
      "LR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.97      0.95      2683\n",
      "    Positive       0.89      0.75      0.82       875\n",
      "\n",
      "    accuracy                           0.92      3558\n",
      "   macro avg       0.91      0.86      0.88      3558\n",
      "weighted avg       0.92      0.92      0.91      3558\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.97      0.95      2683\n",
      "    Positive       0.89      0.79      0.84       875\n",
      "\n",
      "    accuracy                           0.92      3558\n",
      "   macro avg       0.91      0.88      0.89      3558\n",
      "weighted avg       0.92      0.92      0.92      3558\n",
      "\n",
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.98      0.95      2683\n",
      "    Positive       0.91      0.74      0.82       875\n",
      "\n",
      "    accuracy                           0.92      3558\n",
      "   macro avg       0.91      0.86      0.88      3558\n",
      "weighted avg       0.92      0.92      0.92      3558\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.98      0.94      2683\n",
      "    Positive       0.94      0.69      0.80       875\n",
      "\n",
      "    accuracy                           0.91      3558\n",
      "   macro avg       0.92      0.84      0.87      3558\n",
      "weighted avg       0.91      0.91      0.91      3558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count Vectorizer Intensity\n",
    "print(\"GBM\")\n",
    "print(classification_report(y_test,predsGB))\n",
    "print(\"GNB\")\n",
    "print(classification_report(y_test,predsGNB))\n",
    "print(\"ETC\")\n",
    "print(classification_report(y_test,predsETC))\n",
    "print(\"LR\")\n",
    "print(classification_report(y_test,predsLR))\n",
    "print(\"SGD\")\n",
    "print(classification_report(y_test,predSGD))\n",
    "print(\"Voting Classifier\")\n",
    "print(classification_report(y_test,predictionVC))\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_test,preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.875892857142857\n",
      "4480\n",
      "17364\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "values=0\n",
    "for i in range(len(data)):\n",
    "    if data['app_id'][i]=='com.ffgames.racingincar2':\n",
    "        values=values+1\n",
    "        #print(data['rating'][i])\n",
    "        count =count+data['rating'][i]\n",
    "print(count/values)\n",
    "print(values)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.6301111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1704\n",
      "          2       0.33      0.02      0.04       640\n",
      "          3       0.33      0.05      0.08       829\n",
      "          4       0.34      0.03      0.06      1177\n",
      "          5       0.68      0.94      0.79      4650\n",
      "\n",
      "avg / total       0.55      0.63      0.54      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CommunicationSentiment=[]\n",
    "CommunicationSentiment=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[1]:\n",
    "            CommunicationSentiment.append(data['reviews'][i])\n",
    "            CommunicationSentiment.append(data['rating'][i])\n",
    "y =CommunicationSentiment\n",
    "X=CommunicationSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.7051272370308842\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.45      0.54      1583\n",
      "          2       0.33      0.02      0.04       377\n",
      "          3       0.35      0.06      0.10       925\n",
      "          4       0.30      0.03      0.05      1589\n",
      "          5       0.72      0.97      0.83      8769\n",
      "\n",
      "avg / total       0.63      0.71      0.63     13243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ActionSentiment=[]\n",
    "ActionRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[2]:\n",
    "            ActionSentiment.append(data['reviews'][i])\n",
    "            ActionRating.append(data['rating'][i])\n",
    "y =ActionRating\n",
    "X=ActionSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.7430884999182071\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.26      0.37       660\n",
      "          2       0.32      0.03      0.06       230\n",
      "          3       0.34      0.08      0.13       739\n",
      "          4       0.35      0.04      0.08      1612\n",
      "          5       0.76      0.98      0.85      8985\n",
      "\n",
      "avg / total       0.67      0.74      0.67     12226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ArcadeSentiment=[]\n",
    "ArcadeRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[3]:\n",
    "            ArcadeSentiment.append(data['reviews'][i])\n",
    "            ArcadeRating.append(data['rating'][i])\n",
    "y =ArcadeRating\n",
    "X=ArcadeSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=2)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.6899759422614274\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.49      0.50       591\n",
      "          2       0.20      0.01      0.02       199\n",
      "          3       0.33      0.05      0.08       459\n",
      "          4       0.31      0.04      0.07       891\n",
      "          5       0.72      0.97      0.83      4095\n",
      "\n",
      "avg / total       0.60      0.69      0.61      6235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CasualSentiment=[]\n",
    "CasualRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[4]:\n",
    "            CasualSentiment.append(data['reviews'][i])\n",
    "            CasualRating.append(data['rating'][i])\n",
    "y =CasualRating\n",
    "X=CasualSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.6679677970236643\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.58      0.32      0.41       594\n",
      "          2       0.26      0.03      0.05       314\n",
      "          3       0.28      0.06      0.09       516\n",
      "          4       0.37      0.10      0.16      1493\n",
      "          5       0.70      0.97      0.81      5281\n",
      "\n",
      "avg / total       0.58      0.67      0.59      8198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "WeatherSentiment=[]\n",
    "WeatherRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[5]:\n",
    "            WeatherSentiment.append(data['reviews'][i])\n",
    "            WeatherRating.append(data['rating'][i])\n",
    "y =WeatherRating\n",
    "X=WeatherSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sports', 'Communication', 'action', 'Arcade',\n",
       "       'Video Players & Editors', 'Weather', 'card', 'photography',\n",
       "       'Shopping', 'Health & Fitness', 'Finance', 'Casual', 'Medical',\n",
       "       'Racing'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.7016246805403432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.38      0.46      1008\n",
      "          2       0.41      0.02      0.04       378\n",
      "          3       0.40      0.05      0.09       708\n",
      "          4       0.35      0.04      0.07      1521\n",
      "          5       0.72      0.98      0.83      7341\n",
      "\n",
      "avg / total       0.62      0.70      0.61     10956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CardSentiment=[]\n",
    "CardRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[6]:\n",
    "            CardSentiment.append(data['reviews'][i])\n",
    "            CardRating.append(data['rating'][i])\n",
    "y =CardRating\n",
    "X=CardSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.728925353925354\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.60      0.57      1006\n",
      "          2       0.38      0.05      0.09       422\n",
      "          3       0.41      0.11      0.17       830\n",
      "          4       0.38      0.04      0.07      1679\n",
      "          5       0.76      0.98      0.86      8495\n",
      "\n",
      "avg / total       0.66      0.73      0.65     12432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PhotoSentiment=[]\n",
    "PhotoRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[7]:\n",
    "            PhotoSentiment.append(data['reviews'][i])\n",
    "            PhotoRating.append(data['rating'][i])\n",
    "y =PhotoRating\n",
    "X=PhotoSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.699623745819398\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.71      0.69      2716\n",
      "          2       0.42      0.01      0.03       548\n",
      "          3       0.43      0.06      0.11       901\n",
      "          4       0.51      0.06      0.11      1856\n",
      "          5       0.72      0.95      0.82      8331\n",
      "\n",
      "avg / total       0.65      0.70      0.63     14352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ShoppingSentiment=[]\n",
    "ShoppingRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[8]:\n",
    "            ShoppingSentiment.append(data['reviews'][i])\n",
    "            ShoppingRating.append(data['rating'][i])\n",
    "y =ShoppingRating\n",
    "X=ShoppingSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.8116222760290557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.06      0.10       238\n",
      "          2       0.00      0.00      0.00       151\n",
      "          3       0.15      0.01      0.01       341\n",
      "          4       0.17      0.01      0.01      1197\n",
      "          5       0.82      1.00      0.90      8398\n",
      "\n",
      "avg / total       0.70      0.81      0.73     10325\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HealthSentiment=[]\n",
    "HealthRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[9]:\n",
    "            HealthSentiment.append(data['reviews'][i])\n",
    "            HealthRating.append(data['rating'][i])\n",
    "y =HealthRating\n",
    "X=HealthSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.6387904559414127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.77      0.64      1802\n",
      "          2       0.20      0.01      0.02       367\n",
      "          3       0.21      0.01      0.02       591\n",
      "          4       0.40      0.06      0.10      1214\n",
      "          5       0.69      0.88      0.77      4492\n",
      "\n",
      "avg / total       0.56      0.64      0.56      8466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FinanceSentiment=[]\n",
    "FinanceRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[10]:\n",
    "            FinanceSentiment.append(data['reviews'][i])\n",
    "            FinanceRating.append(data['rating'][i])\n",
    "y =FinanceRating\n",
    "X=FinanceSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.7534246575342466\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.19      0.29       818\n",
      "          2       0.06      0.00      0.00       390\n",
      "          3       0.40      0.07      0.12       943\n",
      "          4       0.32      0.03      0.06      1832\n",
      "          5       0.77      0.98      0.86     11785\n",
      "\n",
      "avg / total       0.66      0.75      0.67     15768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CasualSentiment=[]\n",
    "CasualRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[11]:\n",
    "            CasualSentiment.append(data['reviews'][i])\n",
    "            CasualRating.append(data['rating'][i])\n",
    "y =CasualRating\n",
    "X=CasualSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.7704485488126649\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.32      0.42       222\n",
      "          2       0.14      0.01      0.02        96\n",
      "          3       0.45      0.04      0.07       241\n",
      "          4       0.44      0.06      0.10      1149\n",
      "          5       0.78      0.98      0.87      5493\n",
      "\n",
      "avg / total       0.70      0.77      0.70      7201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MedicalSentiment=[]\n",
    "MedicalRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[12]:\n",
    "            MedicalSentiment.append(data['reviews'][i])\n",
    "            MedicalRating.append(data['rating'][i])\n",
    "y =MedicalRating\n",
    "X=MedicalSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.7408776344762504\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.42      0.52       955\n",
      "          2       0.39      0.03      0.05       275\n",
      "          3       0.37      0.09      0.14       757\n",
      "          4       0.42      0.04      0.08      1631\n",
      "          5       0.75      0.98      0.85      9098\n",
      "\n",
      "avg / total       0.67      0.74      0.67     12716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RacingSentiment=[]\n",
    "RacingRating=[]\n",
    "for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[13]:\n",
    "            RacingSentiment.append(data['reviews'][i])\n",
    "            RacingRating.append(data['rating'][i])\n",
    "y =RacingRating\n",
    "X=RacingSentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=10)\n",
    "preds = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32280, 30000, 44141, 40751, 20781, 27324, 36520, 41440, 47840, 34415, 28220, 52560, 24002, 42384]\n"
     ]
    }
   ],
   "source": [
    "counterCategory=[]\n",
    "total=[]\n",
    "count=0\n",
    "category=data.cetagory.unique()\n",
    "for j in range(len(category)):\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if data['cetagory'][i]==category[j]:\n",
    "            count+=1\n",
    "    total.append(count)\n",
    "    count=0\n",
    "print(total)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'cetagory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cetagory'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7aefb8858d9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure_factory\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mff\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnumber_of_apps_in_category\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cetagory'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m data = [go.Pie(\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cetagory'"
     ]
    }
   ],
   "source": [
    "import plotly\n",
    "# connected=True means it will download the latest version of plotly javascript library.\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "number_of_apps_in_category = data['cetagory'].value_counts().sort_values(ascending=True)\n",
    "\n",
    "data = [go.Pie(\n",
    "        labels = number_of_apps_in_category.index,\n",
    "        values = number_of_apps_in_category.values,\n",
    "        hoverinfo = 'label+value'\n",
    "    \n",
    ")]\n",
    "\n",
    "plotly.offline.iplot(data, filename='active_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e86ae93719c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetails\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'app_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Snooker\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "details=data[data['app_name'].str.contains(\"Snooker\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cetagory</th>\n",
       "      <th>app_name</th>\n",
       "      <th>app_id</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Billiards City</td>\n",
       "      <td>com.billiards.city.pool.nation.club</td>\n",
       "      <td>Wonderfull App. Completed all 1020 levels, Ca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Billiards City</td>\n",
       "      <td>com.billiards.city.pool.nation.club</td>\n",
       "      <td>It's good, I like the gameplay. Please change...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Billiards City</td>\n",
       "      <td>com.billiards.city.pool.nation.club</td>\n",
       "      <td>I really enjoyed this game until I saw one of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Billiards City</td>\n",
       "      <td>com.billiards.city.pool.nation.club</td>\n",
       "      <td>PLEASE!!! Get rid of the odd shaped tables an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Billiards City</td>\n",
       "      <td>com.billiards.city.pool.nation.club</td>\n",
       "      <td>Very easy game to play, and has actually give...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cetagory        app_name                               app_id  \\\n",
       "0   Sports  Billiards City  com.billiards.city.pool.nation.club   \n",
       "1   Sports  Billiards City  com.billiards.city.pool.nation.club   \n",
       "2   Sports  Billiards City  com.billiards.city.pool.nation.club   \n",
       "3   Sports  Billiards City  com.billiards.city.pool.nation.club   \n",
       "4   Sports  Billiards City  com.billiards.city.pool.nation.club   \n",
       "\n",
       "                                             reviews  rating  \n",
       "0   Wonderfull App. Completed all 1020 levels, Ca...       5  \n",
       "1   It's good, I like the gameplay. Please change...       4  \n",
       "2   I really enjoyed this game until I saw one of...       1  \n",
       "3   PLEASE!!! Get rid of the odd shaped tables an...       1  \n",
       "4   Very easy game to play, and has actually give...       4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5IAAAFNCAYAAAByhlDBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkqRODJKSJEmSpE7+PyNFojHiDmsDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf7a5a59c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "y = data.rating\n",
    "fig, ax = pyplot.subplots(figsize=(15,5))\n",
    "ax.set_title(\"Most Given Rating\")\n",
    "ax = sns.countplot(y,label=\"Rating Count\",ax=ax,order=data.rating.value_counts().iloc[:10].index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "a=swn.senti_synset('unhappy.a.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_astype_copy_false'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-901009174098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mModule\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mallowing\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mscikit\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \"\"\"\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombine\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\combine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEditedNearestNeighbours\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_adasyn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mADASYN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_random_over_sampler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBorderlineSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeansSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                           estimate_bandwidth, get_bin_seeds)\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0maffinity_propagation_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maffinity_propagation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAffinityPropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m from .hierarchical import (ward_tree, AgglomerativeClustering, linkage_tree,\n\u001b[0m\u001b[0;32m     11\u001b[0m                            FeatureAgglomeration)\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mk_means_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mk_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\hierarchical.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_feature_agglomeration\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAgglomerationTransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_dict\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIntFloatDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_astype_copy_false\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_astype_copy_false'"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "appsentiments=[]\n",
    "for i in range(len(data)):\n",
    "        if data['app_id'][i]=='com.vectorunit.purple.googleplay':\n",
    "            review = re.sub('[^a-zA-Z]', ' ',data['reviews'][i])\n",
    "            review = re.sub('[/(){}\\[\\]\\|@!,;]', ' ',data['reviews'][i])\n",
    "            review = re.sub('[^0-9a-zA-Z #+_♥️]', ' ',data['reviews'][i])#Remove bad symbols\n",
    "            review = re.sub(r'\\d+', '',review)\n",
    "            review = review.lower()\n",
    "            review = review.split()\n",
    "\n",
    "            review = [token for token in review if token not in STOPWORDS]\n",
    "            review=' '.join(review)\n",
    "            appsentiments.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.618973214285714\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "values=0\n",
    "for i in range(len(data)):\n",
    "    if data['app_id'][i]=='com.vectorunit.purple.googleplay':\n",
    "        values=values+1\n",
    "        #print(data['rating'][i])\n",
    "        count =count+data['rating'][i]\n",
    "print(count/values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4480"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "Reviews=[]\n",
    "for i in range(len(data)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ',data['reviews'][i])\n",
    "    review = re.sub('[/(){}\\[\\]\\|@!,;]', ' ',data['reviews'][i])\n",
    "    review = re.sub('[^0-9a-zA-Z #+_♥️]', ' ',data['reviews'][i])#Remove bad symbols\n",
    "    review = re.sub(r'\\d+', '',review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [token for token in review if token not in STOPWORDS]\n",
    "    review=' '.join(review)\n",
    "    Reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderfull app completed levels wait levels level bug get around complete touching two ballt lower left side rail let hand pick wise disappear rail great game loved',\n",
       " 'good like gameplay please change music gets repetitive nd level hear track loop start way many ads also please make mode could break balls instead always levels shoot random balls',\n",
       " 'really enjoyed game saw one adverts throughout ngame man woman spooning hardly appropriate young nchildren see want play innocent game pool nreally todays day age children exposed things ni deleting game hope find one innocence nmind',\n",
       " 'please get rid odd shaped tables go back classic table please fix level balls cue stick disappear table making impossible continue otherwise great game disappointing unable continue end',\n",
       " 'easy game play actually given pointers play nreal game pool like hit cue ball angle place nthe cue stick complaint really ninstructions say acquiring hearts coins points',\n",
       " 'going lie started playing game probably hours ago thoroughly addicted pretty awesome game girl tried taking game attacked like pit bull double fivestar triple thumbs yay',\n",
       " 'level lower left cushion let ball disappear nothingness nafter striking ball seen different edges screen nno way finish level weird fix',\n",
       " 'people balls stop time wont let ball go pocket hand table control game que ball scrach beating game good game controls game good shooter trays make miss pocket',\n",
       " 'gameplay fun graphics good lot levels however number ads insane paid version bothered ads usually try free versions determine game worth buying one seem',\n",
       " 'great game get level starts shooting balls screen see play anymore really fix problem',\n",
       " 'wanted thank supervisors n creator n n charge whatever powers days complaint longer interrupted mid shot advertising ple refer game friends thank listening adam',\n",
       " 'pool player good app find helps using different english techniques control ball well learning various shots encountered league struggled need practice good app',\n",
       " 'wanted basic billiards game redundant tutorial level system totally unecessary map thing show progress weird pool tables political ads galore stop',\n",
       " 'installed game even play game load would shut waste time really wanted play give another review actually works',\n",
       " 'really enjoyed older version alot odd ball ntables aggravating enjoyable know called nbut definitely billards use play hours time nevery',\n",
       " 'really like game certain point normal billiard table changed crooked one hard play game since consider bended corners table hit billiard balls wish could changed back normal billiard table',\n",
       " 'pretty decent game way many ads made watch second video every time wanted retry table thanks unfortunate actually liked',\n",
       " 'level til problem levels balls keep disappearing table way win even keep playing fix pls want take game phone',\n",
       " 'first trouble getting pass level learned uamp level great game finish levels total go back replay levels level bank shots',\n",
       " 'best pool game except try manuver cue left side close power controls shoots barely touch power control trying move cue around annoying thing ever great',\n",
       " 'definitely good game looking kill time play pool graphics point game play hey folks made game next update make u make online play play live players around globe peace',\n",
       " 'level balls well cue ball ends table uamp able complete level otherwise great game play',\n",
       " 'tried bunch pool games always sensitive confusing game awesome abt lettin ya get hang things tossing next level far keepin game phone',\n",
       " 'got games sudden balls would disappear near side rail seen side far rail game screen way reaching q ball leave table love game',\n",
       " 'game cheats know balls defy laws physics cue ball scratches know',\n",
       " 'way way way many ads including second ones dismiss uninstalled minutes',\n",
       " 'game amazing also addictive entertaining nis game anyone likes play games adjust ndirection anything throw roll anything else',\n",
       " 'still put new levels freeze startup period sometimes minute plus keep cache clear hi end phone',\n",
       " 'game good choice disable rays indicator ball goes without helper arrow game would difficult realistic level maybe advanced helper rays disappear maybe',\n",
       " 'plz check stage working properly unable play stage ball automatically get outside table',\n",
       " 'say game stressful u complete game white ball goes hole u lives left u fail even though white ball went hole one u first got hole hate game could would rate zero stars fix level',\n",
       " 'lot ad pass free time youll never get bore last level completed game waiting next update since long update last level',\n",
       " 'one balls disappears hit ball side rails hit balls table empty game lost ball want let game round round mess',\n",
       " 'h e dumbass weird pool table shapes please give us back standard pool tables give us option controls',\n",
       " 'level balls bottom left table disappearing without going hope makes lose game see make last shots',\n",
       " 'good game nice easy play many ads really love tables awesome wish could upgrade kind tricks maybe later game around good pool game make part ill waiting',\n",
       " 'omg got enough ads top inappropriate ones two adults spooning yeah need kids watch much deleted',\n",
       " 'far simplest uncomplicated awesome bestest game pool played mobile platform got hooked since minute downloaded yesterday already reached level thanx keeping game simple devs great work',\n",
       " 'competitive u aint challenging opponent cup championship jus routine stages makes boring jus graphics dope',\n",
       " 'like much balls started sinking side rails uninstalled chose pool got one back back want pool billiards time',\n",
       " 'one made absolutely good keep making mewati function many levels finished tired playing games game good',\n",
       " 'hate bimbo ad care ads women shaking',\n",
       " 'u r greedy many ads son seconds hating game uninstalling u continue many ads u end tens users including urslef',\n",
       " 'first versions actually useful used real table easily see later versions another typical app lifetime designed game user developer pretty trimmings',\n",
       " 'fun game level game glitching really bad let pass next level know going guys need fix',\n",
       " 'cue gets close trgger cue fires finished adjusting button placed away table would give accurate trigger point',\n",
       " 'ads ads ads popping crashing game mention odd shaped tables really billiards rather arcade like',\n",
       " 'great game except cue draw wrong place setting shot keep shooting accidental touch',\n",
       " 'game best world think game always game best super really happen game level completely online level two days intelligent mind',\n",
       " 'even u pool table around u u still enjoy game nwith realistic physics really good game awesome',\n",
       " 'billiards city much like geometry actual round pool help love started playing already hooked',\n",
       " 'love billiards game pretty close real thing far physics goes could better play almost daily thanks',\n",
       " 'would star work balls keep flying table days still please help',\n",
       " 'want fix problem level three balls going table play stage let know fast',\n",
       " 'fun game bad kyrsten sinema prostitution add every level uninstalling',\n",
       " 'finished level addictive game pls download disappointed bcz beginning till end lvl till boring advert',\n",
       " 'plays death game glitches level balls roll table bottom bumpers',\n",
       " 'good game level balls fall table bottom table side solid except great challenging game',\n",
       " 'lot fun loads really fast play wait forever opponent take turn',\n",
       " 'enjoy playing app creators could change aspects though would like play real game pool rules etc apps let play online opponent opponent generated app actually playing competition rather potting balls non stop enjoy pool enjoy app',\n",
       " 'awesome game sure keeps uninstall go plus dont like weird pool tables thats classic',\n",
       " 'easy enjoyable play exceptthe co game keeps putting white ball unneccesarily forcing one watch video pvideo pleaseremedythis tthank',\n",
       " 'even get game kicks loading screen half star could',\n",
       " 'awkward get cue position times fault ads minor irritation',\n",
       " 'level got pool balls side roll nthe game finish level please fix',\n",
       " 'really fun play play enjoy playing google ads every round aggravating',\n",
       " 'many ads always popping disturbs music disruption going delete soon',\n",
       " 'graphics great gameplay great something wrong game oh yeah online gamers game best game ever online gamers otherwise game rubbish',\n",
       " 'addictive game challenging like playing real game recommend friends good graphic back day used play pool good game brings back memories',\n",
       " 'game fun play ads added every level played delete game writing review',\n",
       " 'fun game problems game got level balls would disappear screen could finish level',\n",
       " 'need entertaining health soothing brings nmy pressure keeps focused please tell go past nlevel',\n",
       " 'thing would improve game could betwo player games ball could followed took shot birds eye view',\n",
       " 'game really good equally interesting multi player would given stars vs computer vs friends well',\n",
       " 'game play excellent area trouble logging account devices',\n",
       " 'love great way kill time instead watching mindless tv nice graphics music thank',\n",
       " 'great game obviously room improvement especially comes giving bonus think give countdown bonus take',\n",
       " 'rekha amma appa amma appa amma house gone game ft game game game game game game game game game released game thrones good morning go house amma house ft shool first one love appa amma appa rao road amma thrones stills appa appa rao nagar hyderabad',\n",
       " 'please fix level balls bottom go table hit',\n",
       " 'addictive easy control strategize whenever play actual game pool real life super fun helps angle shots precisely get better real game',\n",
       " 'ball pool give balls get pockets',\n",
       " 'suck pool table costs money play poorly guess means realistic billiards experience kinda enjoy app',\n",
       " 'good game excellent physics thing uncomfortable game garish home screen billiards elegant game home screen match grandeur game',\n",
       " 'really used enjoy game fix level balls disappearing table move forward uninstalling',\n",
       " 'loved game level since stupid shaped tables appeared nhaven played delete',\n",
       " 'absolutely love game first like way easy progress like hold wait min actually starting get challenging love game',\n",
       " 'fun ads started playing game literally every shot sometimes shot uninstalled real quick sure review show',\n",
       " 'west ur data download app worst game ever two time download game game open heted thi game',\n",
       " 'game great graphics realistic action function cue nstick however little squirrelly still lots fun',\n",
       " 'problem game balls disappear bottom frame able proceed beyond',\n",
       " 'reached level working properly control stick see white ball',\n",
       " 'realy like got level stopped finished next level start next',\n",
       " 'one greatest app get moment start playing stop love',\n",
       " 'time wasted time download open game putang ena',\n",
       " 'love game one favorite real life activities playing pool nights week enjoy playing game lot nice feel',\n",
       " 'great graphics bright vibrant like two player actual game pool rather gives feel practice mode',\n",
       " 'game relax love keep games guys download game n another thing game many ads',\n",
       " 'level bug makes balls come table making hard complete level',\n",
       " 'much advertising every time retry next level another ad anoying never click ad',\n",
       " 'nice one thing wana sugesst u limited game multiplayer chalange online playing system like ball pool every level game type sequence balls arrangements boring sometime also thats way give stars unlike overall good thinking good production exelent',\n",
       " 'awesome game easy use addictive played offline many levels need currency options spend anything skills variety levels awesome game best pool game',\n",
       " 'game kind boring much terms challenge advertising entertaining game',\n",
       " 'loved game however fluidity moving cue stick could better somehow feels heavy move desired position',\n",
       " 'dump app multi player even computer compete levels told wanted levels long like river nile full different ads ads let enjoy game self',\n",
       " 'like game really ad every single game annoying',\n",
       " 'audio forced ads make unusable thinking',\n",
       " 'good game level error graphics able compete ball disappear table edge kindly rectify',\n",
       " 'game cheats way many advertisements line shot still misses',\n",
       " 'billiard city one addictive pool shooters ever played physics shots near perfect granted simply shoot balls occasionally goofy tables hate z shaped table table table think get boring keeps getting better uamp better try starting bc anonymous groups soon addiction scary',\n",
       " 'name aruni anand age years liked game much share friends',\n",
       " 'great game good play gets challenging progress please change music would great add colour table levels',\n",
       " 'first time addictive game really love good job guys thanks',\n",
       " 'great game good table needs cue options better challenge game play friends',\n",
       " 'great app pass time addictive completed levels ads annoying',\n",
       " 'lots ads great game wish directional lines balls longer',\n",
       " 'many adds every table makes want uninstall whole thing',\n",
       " 'good game stop add every stroke bcz difficult nconcentrate play game',\n",
       " 'game nice million ads killing ads start popping even enter game',\n",
       " 'levels good game good graphic enough levels please add fix problem',\n",
       " 'awesome go got ir go',\n",
       " 'enjoyed game level balls wall going wall finish round',\n",
       " 'lovely addictive game downloaded stop playing love',\n",
       " 'think may interesting realistic also clue hint available players also designed realistic money earnings sources',\n",
       " 'love game level hope still waiting see next chapter',\n",
       " 'game best beginners easily learn pot ball help play balls snooker',\n",
       " 'bad game bha phaltu kat la tha ha point',\n",
       " 'good time killer gets bit repetitive quickly good snooker buffs',\n",
       " 'always love pool one even better get play specially winter',\n",
       " 'game aap superb means amazing game really like game aap love much much',\n",
       " 'like game like app want play ball competition app greatest graphics seen video game billiards',\n",
       " 'open try play always closed automatically',\n",
       " 'game good enjoyed lot one problem add every game plz work',\n",
       " 'little waste time good uamp time pass many ads coming nirritated',\n",
       " 'game ok full billiards game good kill time',\n",
       " 'many ads one level try means every nseconds watching ad download',\n",
       " 'kiss ass billiards game everyone needs try',\n",
       " 'hate music challenge need aiming thing',\n",
       " 'played number times never get bored',\n",
       " 'get started hard addictive game put love recommend',\n",
       " 'great game bug level prevents playing fun game please fix',\n",
       " 'level gets annoying repetitive',\n",
       " 'adds come loud mute',\n",
       " 'highly recommened makes ball pool look bad',\n",
       " 'ball goes table anybody play ball table saying level',\n",
       " 'sometimes get free ball sunk glove takes best shot',\n",
       " 'entirely many advertising advertisers get way playing',\n",
       " 'amazing yaar really like game lot cool awesome enjoy game much',\n",
       " 'great pool game good trick shots challenging trying pot balls without miss different types pool tables great game',\n",
       " 'nivel las bolas se salen de la mesa desaparecen por lo tanto se puede avanzar de nivel',\n",
       " 'nice easy time waster music annoying cue control bit erratic overall pretty good',\n",
       " 'good challenging game accuracy movements graphics really great rebounds sound effects spot like game',\n",
       " 'game soo stupid point playing incentive continue playing',\n",
       " 'much ads good game great cualidy like im playing real life',\n",
       " 'boring game mai install kr k phs gaya dont install',\n",
       " 'nice game also one thing connect friends also',\n",
       " 'n',\n",
       " 'like wish line travel went ball hole',\n",
       " 'chance get n game chance game play bullet',\n",
       " 'fun pressure anyone computer learning position stick hit ball hard soft enough fun',\n",
       " 'amongst paraphernalia high stress apps relax zone',\n",
       " 'game good insert practice module customizable',\n",
       " 'like game much want tell music good plzz change music game awesome',\n",
       " 'like game ad volumes keep cutting music get rid nthese ads bruh',\n",
       " 'rack em wouuld like break',\n",
       " 'game bad dowload poor game',\n",
       " 'bad thought play match computer person looks like pot balls play match',\n",
       " 'really cool game needs able play eightball nineball games one self',\n",
       " 'beautifully laid addictive best kind well done',\n",
       " 'load bollocks ball potting adverts controls dodgy also',\n",
       " 'think challenging levels game easy levels looking forward levels',\n",
       " 'please fix round ball error',\n",
       " 'good grafix good control worst ads never get level ads',\n",
       " 'far better ball pool miniclip tension loosing coins enjoy shots',\n",
       " 'good adds headache every level play days uninstall game unnecessary adds thk u',\n",
       " 'make u loose one heart instead two add power ups obstacle power ups make tricky',\n",
       " 'good game levels matches',\n",
       " 'gameplay decent ad everything use blocker otherwise skip game',\n",
       " 'like game interesting real pool player think everyone else going enjoy well',\n",
       " 'way many adverts makes hard play interest',\n",
       " 'game makes think strategy able make combos bank shots enjoying game',\n",
       " 'great game ever played challenges category much adds also hope fixed',\n",
       " 'amazing game many ads also interesting love game lot',\n",
       " 'game gets boring tables turn back normal configuration around level +',\n",
       " 'one time favorite games play game helps teach son play loves',\n",
       " 'game sucks worth time play',\n",
       " 'tried several pool games best far',\n",
       " 'brilliant game sometimes boring also sister really good game',\n",
       " 'like game many times ads please',\n",
       " 'many goddamn pop ups every f minute even play comfortable without f pop coming every f seconds f game f pop ups uninstalling',\n",
       " 'enjoyed playing game hate commercials',\n",
       " 'good make online connection game better',\n",
       " 'started playing addictive nice graphics thanks designers making',\n",
       " 'feel great game play different',\n",
       " 'challenges u play alone scoring non stop levels',\n",
       " 'addicting game good way kill unnecessary time waiting',\n",
       " 'great fun like real pool great practice',\n",
       " 'one hell game love addictive fun play',\n",
       " 'stuck level level',\n",
       " 'want table design',\n",
       " 'love game good time play game',\n",
       " 'nice game hv option play friends online',\n",
       " 'almost like real thing surprised',\n",
       " 'boring really fedup game',\n",
       " 'nice game addictive althought make match great game',\n",
       " 'sangat best saya suka sangat game ni thanks mountain games',\n",
       " 'really fun would fun play friends people around world',\n",
       " 'good relaxing game playing real billiard pool game',\n",
       " 'level black hole glitch lower lftrail',\n",
       " 'like game much wonderful game im enjoying told many friends',\n",
       " 'many ads dodgy ones much random pool game',\n",
       " 'want turn que might accidently use power bar',\n",
       " 'great room develop skills easy never impossibly hard',\n",
       " 'good game got level malfunctions balls outside table',\n",
       " 'love new whack tables makes great challenge',\n",
       " 'addictive fun game play also relaxing',\n",
       " 'beautiful app nice graphics good game like much',\n",
       " 'zero complaints one fun addictive',\n",
       " 'awesome game easier play ball pool',\n",
       " 'wish trick shots ecplaination someyhing tto show howt',\n",
       " 'good app useful app refreshes mind please download game please request',\n",
       " 'nice stop play level level',\n",
       " 'creat game completed levels please levels',\n",
       " 'great game let get past level frustrating',\n",
       " 'terrible game wants go homeless',\n",
       " 'repetitive much way challenge',\n",
       " 'th level add pops every shot pool game advertising agency',\n",
       " 'good game controls easy love game',\n",
       " 'lovely game completed level hard',\n",
       " 'great app hate ads',\n",
       " 'okay study game figure',\n",
       " 'wow best game ever seen',\n",
       " 'brilliant gameplay graphics etc thing like ads',\n",
       " 'fiddly controls silly shaped tables loudest adds possible',\n",
       " 'great game frequancy adds become annoying',\n",
       " 'game fun really passes time like believe',\n",
       " 'love game easy play nice game',\n",
       " 'really enjoy simple game pool like real pool aiming',\n",
       " 'really unswer dream enjoying game much',\n",
       " 'addictii n time consuming keep guys',\n",
       " 'game addicting lose track time',\n",
       " 'pretty much expect ads every minutes',\n",
       " 'game fun sometimes quite match pool logic',\n",
       " 'pool app interesting critically',\n",
       " 'addictive game stopi stop playing',\n",
       " 'sudah habis level nya buat apa mulai dari awal lagi',\n",
       " 'game got clearest view also goodbgame improve skills',\n",
       " 'good graphics entertaining keeps mind toes relaxes',\n",
       " 'awesome simply fun game please update game',\n",
       " 'way realistic pool games mad easier entertaining addicting',\n",
       " 'good idea put upgrades game put needs worked',\n",
       " 'like game interesting game clear levels',\n",
       " 'good game really like want many game',\n",
       " 'well like different style tables pay attention balls placed one shot could clear table',\n",
       " 'stages r timepass interesting game',\n",
       " 'love game gets challenging fun',\n",
       " 'good graphics gameplay liked game much challenging interesting best gameplay',\n",
       " 'completed levels awsum game loved level bug u cross dat everything easy complete',\n",
       " 'nice game please create something like powers achievements',\n",
       " 'fun game hard yet anyways lol',\n",
       " 'amazing game develop self mind never ever give',\n",
       " 'like balls disappears threw rails',\n",
       " 'interesting like',\n",
       " 'like game graphics low mb',\n",
       " 'one best pool games ever played',\n",
       " 'best teaching tool far billiards ago found ever',\n",
       " 'like real thing thanks',\n",
       " 'needs clarity nice addicting',\n",
       " 'addict one crossed level days',\n",
       " 'nice game controls good time killer',\n",
       " 'fun entertaint game level still want continue next level stuck',\n",
       " 'game lovely surpassed initial expectation',\n",
       " 'thanks ry much fir relaxation game keeps troubles',\n",
       " 'nice nice game like much like happy game',\n",
       " 'love game graphics good much adds',\n",
       " 'really good never thought billiards could interesting',\n",
       " 'boring game please add online matches',\n",
       " 'best pool game found',\n",
       " 'like game got biggie level reload memes starting',\n",
       " 'think dad would love game',\n",
       " 'even let open dam app',\n",
       " 'nice relaxing game could less adverts otherwise would given five stars',\n",
       " 'like game much becase game usefull game us nthis game internatinal game',\n",
       " 'make vs cpu mode otherwise good time pass',\n",
       " 'multiplayer',\n",
       " 'game fine would like much better turn music player',\n",
       " 'nice gave lives became difficult',\n",
       " 'beautiful game thank great deal stress',\n",
       " 'controls touchy would perfect phone pool game',\n",
       " 'fun would love propper pvp mode',\n",
       " 'lot adds disturbance',\n",
       " 'connected play games account',\n",
       " 'thought good',\n",
       " 'lavel done update please lavels',\n",
       " 'good game chillax',\n",
       " 'helps improve real game enjoy',\n",
       " 'time killing game nice',\n",
       " 'stop going pack finish next levels great job well done',\n",
       " 'love ball shot physics needs pvsp area play',\n",
       " 'since suck real pool love app complaints play hrs makes happy',\n",
       " 'wish could break',\n",
       " 'fun game good controls levels repetitive though',\n",
       " 'great fun could easily kill couple hours game addictive',\n",
       " 'good game us',\n",
       " 'reason wrote stop asking',\n",
       " 'think good keeps da mind things',\n",
       " 'nice game challenge one player makes boring',\n",
       " 'far many ads',\n",
       " 'finished level exactly month wait levels great job',\n",
       " 'like playing alone get better view game glad option others force play opponent',\n",
       " 'addictive like game alot',\n",
       " 'addictive fun rewarding way pass time',\n",
       " 'absolutely brilliant game thing could less ads',\n",
       " 'gusta es sencillo desafiante al mismo tiempo',\n",
       " 'would star adverts joke',\n",
       " 'real pool game shooting balls pockets',\n",
       " 'good fun game pass time',\n",
       " 'great game play love game ame',\n",
       " 'nice better formal',\n",
       " 'finished redownloaded times games finish like',\n",
       " 'awkward aiming miniclips ball much better',\n",
       " 'really fun requires skill luck like',\n",
       " 'amazing game addicted',\n",
       " 'different city scene instead repeated one throughout levels would nice',\n",
       " 'great game ruined fukcing adverts',\n",
       " 'really like done levels always something improve like background music add levels thank',\n",
       " 'like pool good way get skills',\n",
       " 'nice game girl love',\n",
       " 'graphics good easy follow rules',\n",
       " 'thank much',\n",
       " 'love game addicting',\n",
       " 'many advertisements game play could better option playing simple ball game',\n",
       " 'best game ever made offline awesome cool amazingly fun like shooting actual pool lots lots',\n",
       " 'great game got level iphone game stopped working',\n",
       " 'able open',\n",
       " 'hate game much',\n",
       " 'unable play opponent',\n",
       " 'hate new version game',\n",
       " 'good game amount ads completely ruin',\n",
       " 'crashes game loads',\n",
       " 'like studying exam helps alot',\n",
       " 'super entertaining fun great time killer',\n",
       " 'nice game sometimes addicted',\n",
       " 'adds every minut anoying hell unplayable',\n",
       " 'game fun really helps time fly',\n",
       " 'graphics good game fun addictive controls suck bit',\n",
       " 'great game many ads fun way pass time',\n",
       " 'need one play use money every min get bucks',\n",
       " 'really good control shots',\n",
       " 'loved play',\n",
       " 'game good time pass',\n",
       " 'pool player really like game graphics almost like playing pool real great job developers',\n",
       " 'would like play people',\n",
       " 'nice game fabulous marvellous time passes faster',\n",
       " 'awesome mission',\n",
       " 'good game levels r easy',\n",
       " 'game even load installed',\n",
       " 'love game adverts really annoy version buy stop',\n",
       " 'play close real',\n",
       " 'good game spend time',\n",
       " 'good game levels',\n",
       " 'time consuming',\n",
       " 'game brain wont match',\n",
       " 'became disinteresting change shape pool table',\n",
       " 'must bi old perfact players new commers bi tips ftsh commets',\n",
       " 'nice game advertisement bad',\n",
       " 'thanks like wish english application hum better maybe different area enjoyed',\n",
       " 'completed levels loved every minute thanks',\n",
       " 'many ads',\n",
       " 'complicated first time players refreshing end goal tofinish defeat opponent',\n",
       " 'good game play addictive',\n",
       " 'release lite version weaker smart phones',\n",
       " 'play games game work',\n",
       " 'best billiards game played platform',\n",
       " 'new cant figure im saposed thought pool game need work instructions',\n",
       " 'good game ur bored',\n",
       " 'good thing game open',\n",
       " 'played every level level ends game',\n",
       " 'entertaining improves skills real game love',\n",
       " 'good game bit boring',\n",
       " 'bad game',\n",
       " 'great game beginner advance',\n",
       " 'pool pool isnt game nice work guys',\n",
       " 'good game love learning alot',\n",
       " 'many ads love game',\n",
       " 'many ads beginning ads get ton',\n",
       " 'excellent game issues best new bees',\n",
       " 'let play games made final comment',\n",
       " 'many adds called add app play pool sometimes',\n",
       " 'makes u feel like pool pro',\n",
       " 'every super game like much telugu',\n",
       " 'good one really love game',\n",
       " 'awesome game played games worst best',\n",
       " 'best game ever played android pool avail full game mode cool',\n",
       " 'nice game b amazing graphics double team options',\n",
       " 'wow nice game',\n",
       " 'thank wonderful game add feature wherein remove directional line',\n",
       " 'keeps busy like ads constantly',\n",
       " 'really like excellent game lots fun recommended pool entuciast body like well made games',\n",
       " 'bad game hate game boring game',\n",
       " 'want new games',\n",
       " 'get next level',\n",
       " 'graphics great tune catchy',\n",
       " 'nice game hone skills',\n",
       " 'better pool games',\n",
       " 'completed level awsome update',\n",
       " 'game cool like',\n",
       " 'never seen like game never',\n",
       " 'sooo good game ever play',\n",
       " 'boring game intrest',\n",
       " 'damn many adds',\n",
       " 'fun game freezes alot hard play',\n",
       " 'change regular pool would better competing players',\n",
       " 'nice game many ads',\n",
       " 'need lot levels completed stars',\n",
       " 'waste time',\n",
       " 'wast worst game world',\n",
       " 'awesome app time paas best app',\n",
       " 'way many adds',\n",
       " 'wish ads go away',\n",
       " 'wait see spinners lol',\n",
       " 'time started',\n",
       " 'think cool opened',\n",
       " 'awesome game good challenge played',\n",
       " 'amazing game play days',\n",
       " 'bagus game nya bikin ketagihan',\n",
       " 'much advertisements testing tolerance',\n",
       " 'game nice loved',\n",
       " 'boring far easy needs proper tables',\n",
       " 'like funny looking tables could use ball ball games',\n",
       " 'great time killer keeps mind working',\n",
       " 'fun best pool game mobile imo',\n",
       " 'game funny double combo funny wispring',\n",
       " 'took many ads deleted advice download game',\n",
       " 'cue stick keeps jumping shot',\n",
       " 'bad game old billiards city game fantastic game',\n",
       " 'make platform play friends',\n",
       " 'good game addictive',\n",
       " 'game really good sometimes feel boring',\n",
       " 'like put spin real game play',\n",
       " 'good game love',\n",
       " 'dont know say',\n",
       " 'dope dope smoke game',\n",
       " 'game cool gets little boring half way',\n",
       " 'bad game',\n",
       " 'need levels levels',\n",
       " 'nice easy relaxing game easy',\n",
       " 'think game good ball pool makes tarhet perfect',\n",
       " 'baddest pool game world load tab',\n",
       " 'get update',\n",
       " 'like much muwaaaaaas',\n",
       " 'ball ball game least',\n",
       " 'really cool game loved',\n",
       " 'nice easy play game',\n",
       " 'love game amazing thanks',\n",
       " 'great want pass time',\n",
       " 'nice game good time pass',\n",
       " 'nice game good graphics',\n",
       " 'good game like',\n",
       " 'wonderful game much enjoying',\n",
       " 'really good app love playing',\n",
       " 'great boredom busting game',\n",
       " 'one best snooker game playstore',\n",
       " 'like game much come school play',\n",
       " 'like game helps direct shot',\n",
       " 'great game need opponent uamp emo sticker improvements game',\n",
       " 'best game know little',\n",
       " 'thank u much nice game self enjoyed lot',\n",
       " 'like game open tablet',\n",
       " 'helps practice regular pool game',\n",
       " 'well thank goal seeing shot',\n",
       " 'cant stop playing',\n",
       " 'open phone model xoli era x',\n",
       " 'could please adds adds every seconds enough',\n",
       " 'levels harder choice',\n",
       " 'good game',\n",
       " 'stop playing',\n",
       " 'stop playing',\n",
       " 'love game awesome',\n",
       " 'realitic straight pool layouts levels',\n",
       " 'awesome interesting ang tym killing lov',\n",
       " 'game good fantastic boring game',\n",
       " 'great game recommend',\n",
       " 'grew pool naturally love playing relaxing',\n",
       " 'feeling happy game please continue making games like',\n",
       " 'people play pool know angles spin cuts definitely enjoy game',\n",
       " 'best mind relief game forever ever always help enjoy u',\n",
       " 'meany add',\n",
       " 'could open times downloaded',\n",
       " 'advertisement every seconds bit much',\n",
       " 'goes games need',\n",
       " 'think makes please enter games',\n",
       " 'fun',\n",
       " 'best game ever',\n",
       " 'loved game',\n",
       " 'sweet game',\n",
       " 'love game',\n",
       " 'nice time pass decent app whole sunday gone cos lol',\n",
       " 'game traning game use ball pool',\n",
       " 'game nise game playars match battar',\n",
       " 'like gate wonderful aids ones thinking blessed',\n",
       " 'nice game like',\n",
       " 'hoping helps real deal',\n",
       " 'cool game kills time',\n",
       " 'downloaded game yesterday hooked',\n",
       " 'good game far pop ups sucks though',\n",
       " 'okay game like much sooooo',\n",
       " 'awesome game',\n",
       " 'realalistic pool game ever played',\n",
       " 'still phone days fun play quick short games brief ads',\n",
       " 'great app playing pool husband daughter play',\n",
       " 'good game easy tight pockets',\n",
       " 'nothing paly yet',\n",
       " 'cannot play opponents',\n",
       " 'yet see levels',\n",
       " 'opening lenovo k note',\n",
       " 'play level intresing',\n",
       " 'funniest #game like',\n",
       " 'option play online players available',\n",
       " 'like much silent mind',\n",
       " 'masth time pass game android phones',\n",
       " 'like need leaves',\n",
       " 'good also bad',\n",
       " 'like game thanku much',\n",
       " 'game based ball pool',\n",
       " 'many levels thid game',\n",
       " 'like odd shaped tables',\n",
       " 'good killing time',\n",
       " 'loved game easy play kill temper hahaha',\n",
       " 'like like play ball',\n",
       " 'challenging thought',\n",
       " 'faaltoo ends last stop',\n",
       " 'good game way many ads',\n",
       " 'bear make better always support',\n",
       " 'good game like alot',\n",
       " 'like game far',\n",
       " 'keeps busy commute',\n",
       " 'connect facebook play friends',\n",
       " 'k think cheers',\n",
       " 'tention free games',\n",
       " 'one best games ever played next one thank alan',\n",
       " 'wont pull city',\n",
       " 'good game network',\n",
       " 'human vs human option needed',\n",
       " 'please make new version game',\n",
       " 'must match like game opponent',\n",
       " 'good game',\n",
       " 'constant ads ruin playability pretty fast',\n",
       " 'super se bhi uper good game like real game graphics good',\n",
       " 'good game like different shape tables ads much',\n",
       " 'nice young people think realistic',\n",
       " 'best snooker game need cross ball pool',\n",
       " 'fun takes alot good strategy planning',\n",
       " 'interesting game',\n",
       " 'far good liked tables traditional',\n",
       " 'game like skilled mind blown trick shot',\n",
       " 'much advertising pls install game',\n",
       " 'like much',\n",
       " 'jai billiards baba',\n",
       " 'get rid vigo video ad',\n",
       " 'bohot accha game ye',\n",
       " 'like game much',\n",
       " 'time game responding',\n",
       " 'kasi abis waktu senang aja',\n",
       " 'essay game also enjoyble',\n",
       " 'balls larger need',\n",
       " 'enjoy quite lot mostly enjoy playing line',\n",
       " 'great game many ads though hard get game back sometimes',\n",
       " 'kuch game hard hona chahiye',\n",
       " 'waaaw ju gud da januw',\n",
       " 'ok need improve',\n",
       " 'go guys enjoyn',\n",
       " 'like game much',\n",
       " 'like game much',\n",
       " 'game good best',\n",
       " 'plz update game',\n",
       " 'game nice',\n",
       " 'amazing game',\n",
       " 'nice game enjoyed',\n",
       " 'best game world',\n",
       " 'past downloaded snooker games found best',\n",
       " 'helps game real',\n",
       " 'fun short geometry different levels new challenge time',\n",
       " 'think game challenging fun daughter likes',\n",
       " 'great way pass time addicted',\n",
       " 'good pool game want single player mode',\n",
       " 'inappropriate ad content',\n",
       " 'keeps going',\n",
       " 'like game much',\n",
       " 'least timer',\n",
       " 'beautiful game awesome play every one nice cool gm',\n",
       " 'lots fun completed levels cant wait levels great time killer',\n",
       " 'much ads',\n",
       " 'nice addition games folder',\n",
       " 'love billiards game pretty close real thing',\n",
       " 'best game ever downloaded category',\n",
       " 'like playing pool one easy control easy see love',\n",
       " 'good game',\n",
       " 'think game interesting',\n",
       " 'easy use one one game play',\n",
       " 'like much',\n",
       " 'uc dir ud rtl ue uc ue',\n",
       " 'nice game',\n",
       " 'say love addictive wont deleting xxxxxx',\n",
       " 'would pay taking ad',\n",
       " 'really appreciate efforts providing us nice addictive game',\n",
       " 'waste stupi',\n",
       " 'best wishes days ago give great game',\n",
       " 'best video pool game ever played keep',\n",
       " 'like changing table',\n",
       " 'love game cool hope guy enjoyed making game',\n",
       " 'thank sair much really enjoyed gams super',\n",
       " 'hard game',\n",
       " 'bom jogo pra relaxar',\n",
       " 'king subedi',\n",
       " 'starting',\n",
       " 'game really sucks',\n",
       " 'multi player support',\n",
       " 'everything reviewed',\n",
       " 'like game',\n",
       " 'play company',\n",
       " 'addective game',\n",
       " 'single player game',\n",
       " 'need online together friends',\n",
       " 'bro plz change bods',\n",
       " 'want like match',\n",
       " 'jugpreet singh gurpreet singh',\n",
       " 'mind shoot game',\n",
       " 'nice app little bit changes',\n",
       " 'look matured',\n",
       " 'challenges gud loved',\n",
       " 'wotha punda maari irruku',\n",
       " 'nice game game soo easy',\n",
       " 'like english feature',\n",
       " 'nice mountain game like much thanks name trisha nice game nice game',\n",
       " 'cool relaxing nice game take stress',\n",
       " 'excellent offline pool app love different table shapes',\n",
       " 'nice good game easy play relaxing music average game like',\n",
       " 'last level',\n",
       " 'record speaks',\n",
       " 'game interesting',\n",
       " 'godam much pub',\n",
       " 'pool tables suck',\n",
       " 'need player partner',\n",
       " 'like play',\n",
       " 'less adds',\n",
       " 'jordar game hai yaar',\n",
       " 'good game relax love',\n",
       " 'oooooooooo jeeeeeeee niiiiiii aaaaaallllllllll',\n",
       " '',\n",
       " 'ya ireaally like app',\n",
       " 'good gameplay lots levels',\n",
       " 'ahhhh fred todd ttygu',\n",
       " 'go high',\n",
       " 'osime tume pass',\n",
       " 'time pass ke liye sahi h',\n",
       " 'bht achaa game ga',\n",
       " 'use google play',\n",
       " 'ok apart adds',\n",
       " 'initiating game',\n",
       " 'super game',\n",
       " 'really enjoy game',\n",
       " 'worst game ever',\n",
       " 'like game',\n",
       " 'boring many ads',\n",
       " 'worst app ever',\n",
       " 'game osome difficult lot f enjoyment',\n",
       " 'many ads',\n",
       " 'really like app game come join crew',\n",
       " 'really nice timekiller well full fun excitement',\n",
       " 'bad bad',\n",
       " 'eliminate ads',\n",
       " 'nice game',\n",
       " 'dirty game controls good',\n",
       " 'keep try made control easy play',\n",
       " 'annoying commercials',\n",
       " 'excellent game stop playing',\n",
       " 'like great job greetings justin nel',\n",
       " 'making easy shots like playing pool real life',\n",
       " 'pizza village',\n",
       " 'graphics improvement required',\n",
       " 'really entertaining different cool shapes challenges',\n",
       " 'good game graphics also good everyone enjoy',\n",
       " 'levels stall good game',\n",
       " 'game provided fun excitment lot joy game really nice',\n",
       " 'nice game boring ringtone',\n",
       " 'game keeps crashing even get use please fix',\n",
       " 'good game play game good game levels hard game',\n",
       " 'love game good challenges challenging',\n",
       " 'awesome game stop playing',\n",
       " 'awesome nice game l love much',\n",
       " 'many ads',\n",
       " 'new table sucks',\n",
       " 'like game',\n",
       " 'many ads',\n",
       " 'good travel time pass wen yo internet',\n",
       " 'lot advisor',\n",
       " 'good app children practice want play accurate',\n",
       " 'superb game like must download',\n",
       " 'great perfect brilliant time waster clean cut game',\n",
       " 'nice little like ball pool',\n",
       " 'good idea play tipe games thanks',\n",
       " 'good also add online matches',\n",
       " 'google user game actually actively nice controlling',\n",
       " 'love playing good time waster found relaxing',\n",
       " 'play lot games best fun pool game found',\n",
       " 'l game',\n",
       " 'quite entertaining game many adverts level progresses',\n",
       " 'awesome game thanks',\n",
       " 'great controls great graphics many ads',\n",
       " 'good',\n",
       " 'interested game getting excitement like love',\n",
       " 'meny advertising otherwise would rate stars',\n",
       " 'barbie games nice want barbie games play levels ok',\n",
       " 'nice addicted game',\n",
       " 'good challenges game',\n",
       " 'nack game',\n",
       " 'started already learning game thank',\n",
       " 'good please really pool game',\n",
       " 'many commercials',\n",
       " 'eh okay guess',\n",
       " 'love love love game much ads still loving',\n",
       " 'like playing game',\n",
       " 'fun frustrating',\n",
       " 'pool rubbish many ads',\n",
       " 'like play',\n",
       " 'giving gets multilayer opt star game',\n",
       " 'challenge',\n",
       " 'make turning pool cue easier faster',\n",
       " 'nice game changes required make challenging',\n",
       " 'game amazing really loved',\n",
       " 'think features adds would great',\n",
       " 'good game good game set mind',\n",
       " 'nice time killing game',\n",
       " 'bata reyes style',\n",
       " 'played pool think cool new one',\n",
       " 'good enjoy',\n",
       " 'like game nice game play tip game game',\n",
       " 'nice game',\n",
       " 'tilt view striker fun',\n",
       " 'nice game',\n",
       " 'good pool game best played yet',\n",
       " 'nice fantastic game many ads mars',\n",
       " 'karan kumar',\n",
       " 'awesome n amazing app',\n",
       " 'passes time',\n",
       " 'fun easy gameenjoying playing',\n",
       " 'good game pass time',\n",
       " 'love pool game especially cool shapes pool table',\n",
       " 'good pool game',\n",
       " 'wow game worth playing',\n",
       " 'love great app thanks',\n",
       " 'player vs player available would best game',\n",
       " 'good best',\n",
       " 'good running app enjoy game easy game',\n",
       " 'fine good',\n",
       " 'hope u give us comment also',\n",
       " 'needs multi player still like',\n",
       " 'game ok',\n",
       " 'good game high guality mode',\n",
       " 'fun game would recommend anyone likes pool',\n",
       " 'great game play relax time',\n",
       " 'many ads',\n",
       " 'addictive game phone',\n",
       " 'awesome fantastic ultra ultimate fabulousest game',\n",
       " 'addicting',\n",
       " 'much adds',\n",
       " 'thanks game playstore',\n",
       " 'nagendra kumar mishra',\n",
       " 'dis game meising',\n",
       " 'mahar saeed thanks',\n",
       " 'fun seems like',\n",
       " 'iv including',\n",
       " 'supar game reyaly',\n",
       " 'like game',\n",
       " '',\n",
       " 'addicting game',\n",
       " 'need controller',\n",
       " 'many adds',\n",
       " 'gd time pass',\n",
       " 'lov game',\n",
       " 'feeling',\n",
       " 'make new update',\n",
       " 'like game',\n",
       " 'se autoriza',\n",
       " 'super se upee',\n",
       " 'mind concentrate game',\n",
       " 'super game',\n",
       " 'gud game',\n",
       " 'time pass game',\n",
       " 'game asem',\n",
       " 'thankyou much',\n",
       " 'like game',\n",
       " 'like game',\n",
       " 'u mum gay',\n",
       " 'plzz give coin stick',\n",
       " 'helps',\n",
       " 'yeh orange yeah',\n",
       " 'sht one',\n",
       " 'many ads',\n",
       " 'game awesomw',\n",
       " 'many ads',\n",
       " 'many adds',\n",
       " 'play others',\n",
       " 'huu hi lg',\n",
       " 'many ads',\n",
       " 'like game',\n",
       " 'time pass game',\n",
       " 'desi game e',\n",
       " 'killin time game',\n",
       " 'interestingly enough',\n",
       " 'session',\n",
       " 'like turtles',\n",
       " 'yet opening',\n",
       " 'many adverts',\n",
       " 'hobbies',\n",
       " 'sorry wanted stars',\n",
       " 'tik hai game',\n",
       " 'manu ads',\n",
       " 'achha game hain',\n",
       " 'ok game play',\n",
       " 'many adds',\n",
       " 'thinks game',\n",
       " 'many adds',\n",
       " 'super game',\n",
       " 'nive game',\n",
       " 'thanks game',\n",
       " 'many ad',\n",
       " 'ilikethis game lot',\n",
       " 'like game',\n",
       " 'like game',\n",
       " 'adds game',\n",
       " 'much adds',\n",
       " 'time pass game',\n",
       " 'put opponents',\n",
       " 'mizanur rahaman excilent',\n",
       " 'awesome',\n",
       " 'nice game like',\n",
       " 'kid loves',\n",
       " 'none stop thinking beautiful tables game nice uamp smooth',\n",
       " 'sometimes need play game good',\n",
       " 'keep adding games without getting interrupted',\n",
       " 'great way learn play pool really helpful',\n",
       " 'likeitso far getting started like graphics',\n",
       " 'great game awesome graphics realistic play',\n",
       " 'really okay love graphics control',\n",
       " 'game fun like billiards games',\n",
       " 'gamw nice play think install game',\n",
       " 'like washroom',\n",
       " 'hi ok play interesting game',\n",
       " 'nice make u understand pools better',\n",
       " 'nice lots pop adds',\n",
       " 'enjoying much put',\n",
       " 'fun game well made easy pick',\n",
       " 'shotting power cue',\n",
       " 'love game one best game world',\n",
       " 'fun game',\n",
       " 'good game like make',\n",
       " 'like good kill time',\n",
       " 'terbaik la star',\n",
       " 'far really fun best pool game far',\n",
       " 'many games like love hit billards',\n",
       " 'much better game',\n",
       " 'ball looks real enjoyed game',\n",
       " 'awesome game play really sports fan',\n",
       " 'game best game realistic grafics',\n",
       " 'great game break',\n",
       " 'game good u found add every step',\n",
       " 'really fun skillful game ages cheers creator',\n",
       " 'nice great good game',\n",
       " 'good one counting numbers snowing',\n",
       " 'interesting game like much',\n",
       " 'like angles fun play nice challenge',\n",
       " 'cool game wayyy tooo many ads',\n",
       " 'like much dont wye lids',\n",
       " 'like help learn play',\n",
       " 'love game sos os much',\n",
       " 'tip carry bad game',\n",
       " 'nice game need part',\n",
       " 'best thing ever n addict game',\n",
       " 'love game plz makes like games',\n",
       " 'good game would better actual ball games',\n",
       " 'cool game entertain good time pass',\n",
       " 'would great game many dam ads',\n",
       " 'much fun hardly stand',\n",
       " 'love game super good control graphics',\n",
       " 'really love game need features',\n",
       " 'pretty good complaints hear',\n",
       " 'ugghhh',\n",
       " 'nice pool game liked',\n",
       " 'ita intresting game butt falt adds',\n",
       " 'wonderful like games type',\n",
       " 'amazing game reached level awesome',\n",
       " 'v nice want play vs',\n",
       " 'open',\n",
       " 'imhussain mustafa',\n",
       " 'awesome ha game super ha game',\n",
       " 'money',\n",
       " '',\n",
       " 'nyc learning nw gud experience',\n",
       " '',\n",
       " 'ok',\n",
       " 'realalistic',\n",
       " 'loved',\n",
       " 'nice game liked much wow',\n",
       " 'love pool game best amazing',\n",
       " 'playing long time liking lots',\n",
       " 'amazing good also thanks create good app',\n",
       " 'best billiard game played',\n",
       " 'u need work game game',\n",
       " 'great game wait levels',\n",
       " 'fun game keeps focused easy enjoyyy',\n",
       " 'fun easy play graphics good',\n",
       " 'game nice game time pass',\n",
       " 'love style pool billards great job',\n",
       " 'think game best game ever seen',\n",
       " 'till ive completed levels looking good',\n",
       " 'digin',\n",
       " 'interesting game graphic quality rich',\n",
       " 'great game help train focus',\n",
       " 'one best pool games played',\n",
       " 'really enjoyed game played games',\n",
       " 'best pool game ever please install game',\n",
       " 'love fun play relaxing',\n",
       " 'realistic recreation playing pool',\n",
       " 'wonderful game app loved much',\n",
       " 'interesting board pattern',\n",
       " 'game intersting piecefull thankyou',\n",
       " 'good problem add',\n",
       " 'awesome way learn master trick shots',\n",
       " 'amazing love game addictive',\n",
       " 'like',\n",
       " 'great billiard game iam searcing',\n",
       " 'good work guys game addictive',\n",
       " 'super game',\n",
       " 'really superb game ed ittt',\n",
       " 'great game except ads btw liked game',\n",
       " 'interesting good time pass',\n",
       " 'great pool game learn angles banks',\n",
       " 'amazing game waiting levels',\n",
       " 'nice game need improve controller',\n",
       " 'ok game easy play',\n",
       " 'like playing game easy play',\n",
       " 'interesting bat money',\n",
       " 'good game kids third class',\n",
       " 'lots lots lots ads fun prepare bazzzzilion ads',\n",
       " 'best fantastic',\n",
       " 'thank found great pool game',\n",
       " 'kept happy hrs straight',\n",
       " 'great app change table',\n",
       " 'nyc app',\n",
       " 'superb game like much',\n",
       " 'ta chido',\n",
       " 'really awsome make pool interesting',\n",
       " 'new player excited',\n",
       " 'great game',\n",
       " 'good game many ads',\n",
       " 'love awe',\n",
       " 'angles pckets need distance pointing',\n",
       " 'little bit odd gr',\n",
       " 'nice game level',\n",
       " 'super',\n",
       " 'love better ball pool',\n",
       " 'good thanks pool city',\n",
       " 'best game ball pool',\n",
       " 'love play game',\n",
       " 'easy use good game',\n",
       " 'love thank bringing board',\n",
       " 'nice g satish phone numbers',\n",
       " 'think really enjoying ggme',\n",
       " '',\n",
       " 'really cool game doubt',\n",
       " 'kinda good game put easy',\n",
       " 'started playing happy far',\n",
       " 'addictive game lot adds',\n",
       " 'nice game good graphics also',\n",
       " 'game easy good controls',\n",
       " 'games still love game',\n",
       " 'think love good game',\n",
       " 'addictive also enjoyable',\n",
       " 'best game played',\n",
       " 'ok passing time sweet melody',\n",
       " 'kool amazing pool game',\n",
       " 'best game ever played',\n",
       " 'need work controls good game',\n",
       " 'good game pass time many ads',\n",
       " 'nice game play hole level',\n",
       " 'easy ball pool',\n",
       " 'important game earth wonderful',\n",
       " 'good game ball pool better',\n",
       " 'interesting game fully time pass',\n",
       " 'awesome game ever seen',\n",
       " 'ii like billiards nice',\n",
       " 'good game like thanks',\n",
       " 'cool shows actually play pool',\n",
       " 'good playing _ p',\n",
       " 'okey',\n",
       " 'bad thank u vrrryuch',\n",
       " 'nice small change',\n",
       " 'cool game base physics concepts',\n",
       " 'graphics totally super cool love game totally awesome dude',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['rating']\n",
    "X=Reviews\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=72684)\n",
    "X_train= vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4480, 72684)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=50)\n",
    "model = rfc.fit(X_train, y_train)\n",
    "#print(\"Random Forest\")\n",
    "#print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble.forest.RandomForestClassifier"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'finalized_model.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-bc3bf5d835e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'finalized_model.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'finalized_model.csv'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.csv'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0aafb7656b8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle as cPickle\n",
    "with open('predict.csv', 'wb') as f:\n",
    "    cPickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:312: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:312: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-915fdc8cc28b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;31m#print(\"Random Forest\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m#print(accuracy_score(y_test, preds))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle as cPickle\n",
    "with open('C:\\\\Users\\\\Muhammad Umer\\\\PycharmProjects\\\\GooglePlayStore\\\\predict.csv', 'rb') as f:\n",
    "    rf = cPickle.load(f)\n",
    "\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "#print(\"Random Forest\")\n",
    "#print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "TfidfVectorizer - Vocabulary wasn't fitted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4798d6e062f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m72684\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mReviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Random Forest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'The tfidf vector is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[1;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vocabulary_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: TfidfVectorizer - Vocabulary wasn't fitted."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=72684)\n",
    "X_test=vectorizer.transform(Reviews)\n",
    "pred = rf.predict(X_test)\n",
    "print(\"Random Forest\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d09c40b57611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappsentiments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "sum(pred)/len(appsentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 categories\n",
      "\n",
      " ['Sports' 'Communication' 'action' 'Arcade' 'Video Players & Editors'\n",
      " 'Weather' 'card' 'photography' 'Shopping' 'Health & Fitness' 'Finance'\n",
      " 'Casual' 'Medical' 'Racing']\n"
     ]
    }
   ],
   "source": [
    "print( len(data['cetagory'].unique()) , \"categories\")\n",
    "\n",
    "print(\"\\n\", data['cetagory'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKIAAALMCAYAAADXShqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from matplotlib import pyplot\n",
    "import plotly.graph_objs as go\n",
    "%matplotlib inline\n",
    "fig, ax = pyplot.subplots(figsize=(20,10))\n",
    "g = sns.countplot(x=\"cetagory\",data=data, hue=data.rating)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "plt.title('Count of app in each category',size = 20)\n",
    "plt.savefig('Count of app in each categorys.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hoverinfo": "label+value",
         "labels": [
          "Video Players & Editors",
          "Medical",
          "Weather",
          "Finance",
          "Communication",
          "Sports",
          "Health & Fitness",
          "card",
          "Arcade",
          "photography",
          "Racing",
          "action",
          "Shopping",
          "Casual"
         ],
         "type": "pie",
         "values": [
          20781,
          24002,
          27324,
          28220,
          30000,
          32280,
          34415,
          36520,
          40751,
          41440,
          42384,
          44141,
          47840,
          52560
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"fa40f9b1-0f16-4170-a86e-08b602eb79e2\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"fa40f9b1-0f16-4170-a86e-08b602eb79e2\", [{\"labels\": [\"Video Players & Editors\", \"Medical\", \"Weather\", \"Finance\", \"Communication\", \"Sports\", \"Health & Fitness\", \"card\", \"Arcade\", \"photography\", \"Racing\", \"action\", \"Shopping\", \"Casual\"], \"values\": [20781, 24002, 27324, 28220, 30000, 32280, 34415, 36520, 40751, 41440, 42384, 44141, 47840, 52560], \"type\": \"pie\", \"hoverinfo\": \"label+value\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"fa40f9b1-0f16-4170-a86e-08b602eb79e2\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"fa40f9b1-0f16-4170-a86e-08b602eb79e2\", [{\"labels\": [\"Video Players & Editors\", \"Medical\", \"Weather\", \"Finance\", \"Communication\", \"Sports\", \"Health & Fitness\", \"card\", \"Arcade\", \"photography\", \"Racing\", \"action\", \"Shopping\", \"Casual\"], \"values\": [20781, 24002, 27324, 28220, 30000, 32280, 34415, 36520, 40751, 41440, 42384, 44141, 47840, 52560], \"type\": \"pie\", \"hoverinfo\": \"label+value\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "# connected=True means it will download the latest version of plotly javascript library.\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "number_of_apps_in_category = data['cetagory'].value_counts().sort_values(ascending=True)\n",
    "\n",
    "data = [go.Pie(\n",
    "        labels = number_of_apps_in_category.index,\n",
    "        values = number_of_apps_in_category.values,\n",
    "        hoverinfo = 'label+value'\n",
    "    \n",
    ")]\n",
    "\n",
    "plotly.offline.iplot(data, filename='active_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, we import the relevant modules from the NLTK library\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# next, we initialize VADER so we can use it within our Python script\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sentimentScore=[]\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(appsentiments)):    \n",
    "    message_text = appsentiments[i]\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    scores = sid.polarity_scores(message_text)\n",
    "    sentimentScore.append(scores['compound'])\n",
    "# Here we loop through the keys contained in scores (pos, neu, neg, and compound scores) and print the key-value pairs on the screen\n",
    "\n",
    "#print(scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5423"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = sid.polarity_scores('I am bad boy')\n",
    "scores['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46316624999999484"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sentimentScore)/len(appsentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124238\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "biasedReview=[]\n",
    "Newrating=[]\n",
    "biasedRating=[]\n",
    "#rat=[]\n",
    "count=0\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(data)):   \n",
    "    #message_text = 'i hate you'\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    b = TextBlob(data.reviews[i])\n",
    "    #scores = sid.polarity_scores(data.reviews[i])\n",
    "    value=b.sentiment[0]\n",
    "    #value=scores['neg']\n",
    "    rat=data.rating[i]\n",
    "    if value<=0 and rat >2.5:\n",
    "        count=count+1\n",
    "        biasedReview.append(data.reviews[i])\n",
    "        biasedRating.append(rat)\n",
    "    else:\n",
    "        Newrating.append(rat)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124238\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "biasedReview=[]\n",
    "Newrating=[]\n",
    "biasedRating=[]\n",
    "#rat=[]\n",
    "count=0\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(data)):   \n",
    "    #message_text = 'i hate you'\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    b = TextBlob(data.reviews[i])\n",
    "    #scores = sid.polarity_scores(data.reviews[i])\n",
    "    value=b.sentiment[0]\n",
    "    #value=scores['neg']\n",
    "    rat=data.rating[i]\n",
    "    if value<=0 and rat >2.5:\n",
    "        count=count+1\n",
    "        biasedReview.append(data.reviews[i])\n",
    "        biasedRating.append(rat)\n",
    "    else:\n",
    "        Newrating.append(rat)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134079\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "biasedReview=[]\n",
    "Newrating=[]\n",
    "biasedRating=[]\n",
    "#rat=[]\n",
    "from textblob import TextBlob\n",
    "count=0\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(data)):   \n",
    "    #message_text = 'i hate you'\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    b = TextBlob(data.reviews[i])\n",
    "    #scores = sid.polarity_scores(data.reviews[i])\n",
    "    value=b.sentiment[0]\n",
    "    #value=scores['neg']\n",
    "    rat=data.rating[i]\n",
    "    if value<=0 and rat >=2:\n",
    "        count=count+1\n",
    "        biasedReview.append(data.reviews[i])\n",
    "        biasedRating.append(rat)\n",
    "    else:\n",
    "        Newrating.append(rat)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(biasedRating)\n",
    "#The game cheats and way too many advertisemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithTwoRating = pd.DataFrame(\n",
    "    {'biasedRating': biasedRating,\n",
    "     'biasedReview': biasedReview\n",
    "     \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    89034\n",
       "4    20479\n",
       "3    14725\n",
       "2     9841\n",
       "Name: biasedRating, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWithTwoRating.biasedRating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134079"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWithTwoRating.biasedRating.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    247747\n",
       "1     49608\n",
       "4     47940\n",
       "3     17513\n",
       "2      5764\n",
       "0         7\n",
       "Name: Newrating, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWithTwoRatingNew = pd.DataFrame(\n",
    "    {'Newrating': Newrating\n",
    "     \n",
    "    })\n",
    "dfWithTwoRatingNew.Newrating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    336781\n",
       "4     68419\n",
       "1     49608\n",
       "3     32238\n",
       "2     15605\n",
       "0         7\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biasedRating</th>\n",
       "      <th>biasedReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Very easy game to play, and has actually give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm not going to lie.I just started playing t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   biasedRating                                       biasedReview\n",
       "0             4   Very easy game to play, and has actually give...\n",
       "1             5   I'm not going to lie.I just started playing t..."
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'biasedRating': biasedRating,\n",
    "     'biasedReview': biasedReview\n",
    "     \n",
    "    })\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'BiasedDataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    89034\n",
       "4    20479\n",
       "3    14725\n",
       "Name: biasedRating, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.to_csv(r'BiasedDataset.csv')\n",
    "df.biasedRating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {'NewRating': Newrating\n",
    "     \n",
    "    })\n",
    "df1.head(2)\n",
    "df1.to_csv(r'BiasedDatasetNewRating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    247747\n",
       "1     49608\n",
       "4     47940\n",
       "3     17513\n",
       "2     15605\n",
       "0         7\n",
       "Name: NewRating, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.NewRating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124238"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biasedReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biasedRating.count(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124238\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sentimentScore=[]\n",
    "#rat=[]\n",
    "count=0\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "for i in range(len(data)):   \n",
    "    #message_text = 'i hate you'\n",
    "\n",
    "#print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    b = TextBlob(data.reviews[i])\n",
    "    #scores = sid.polarity_scores(data.reviews[i])\n",
    "    value=b.sentiment[0]\n",
    "    #value=scores['neg']\n",
    "    rat=data.rating[i]\n",
    "    if value<=0 and rat > 2.5:\n",
    "        count=count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)): \n",
    "    if data.cetagory=='Sports':\n",
    "        sportsReviews.append(data.re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xc30da837f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBsAAAF1CAYAAACphOJJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZKkVjlskCRJkiRJrfof67i/LyyMUyoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc30d485dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x1=[0.72791,0.69333,0.67375,0.71955]\n",
    "x2=[0.69958,0.70375,0.70575,0.71041]\n",
    "# Data\n",
    "df=pd.DataFrame({'x': range(0,4), 'Random Forest': x1, 'Gradient Boosting Classifier': x2})\n",
    "\n",
    "# multiple line plot\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "ax.set_title(\"Accuracy Comparison of Random Forest & Gradient Boosting Classifier\")\n",
    "plt.plot( 'x', 'Random Forest', data=df, marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4)\n",
    "plt.plot( 'x', 'Gradient Boosting Classifier', data=df, marker='', color='olive', linewidth=2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9IAAAJOCAYAAABbQD9SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neiQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc30cda79e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "#x=category\n",
    "ylist =[64,63,70,74,68,66,70,72,69,81,63,75,77,74]\n",
    "fig, ax = pyplot.subplots(figsize=(15,10))\n",
    "ax.set_title(\"Most Given Rating\")\n",
    "ax = sns.barplot(y=category, x=ylist,ax=ax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category=data.cetagory.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textS='It is great my kids love to play it. Thank you for having this game on game store.'\n",
    "textS=textS.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned=re.sub(r\"(?is)<(script|style).*?>.*?(</\\1>)\", \"\", textS.strip())\n",
    "cleaned =re.sub(r\"(?s)<!--(.*?)-->[\\n]?\", \"\", cleaned)\n",
    "cleaned = re.sub(r\"(?s)<.*?>\", \" \", cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great kids love play . thank game game store .'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(cleaned)\n",
    "result = [i for i in tokens if not i in stop_words]\n",
    "review=' '.join(result)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great kid love play . thank game game store .'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer= PorterStemmer()\n",
    "final=[]\n",
    "input_str=word_tokenize(review)\n",
    "for word in input_str:\n",
    "    final.append(stemmer.stem(word))\n",
    "finals=' '.join(final)\n",
    "finals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>great</th>\n",
       "      <th>kid</th>\n",
       "      <th>love</th>\n",
       "      <th>play</th>\n",
       "      <th>store</th>\n",
       "      <th>thank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game     great       kid      love      play     store     thank\n",
       "0  0.632456  0.316228  0.316228  0.316228  0.316228  0.316228  0.316228"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv1 = TfidfVectorizer()\n",
    "x_traincv = cv1.fit_transform([\"great kid love play . thank game game store .\"])\n",
    "x_traincv_df = pd.DataFrame(x_traincv.toarray(),columns=list(cv1.get_feature_names()))\n",
    "x_traincv_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
